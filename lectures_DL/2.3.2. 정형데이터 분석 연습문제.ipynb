{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NATURE LANGUAGE\n",
    "### 연습문제 1\n",
    "- 초음파 Frequency로 광물-암석 예측하기\n",
    "- 광물과 암석을 종속변수로 하는 pytest/sonar.csv 파일로 이진분류를 수행하시오\n",
    "- 종속변수는 맨 우측 컬럼이며, 나머지는 모두 독립변수이다\n",
    "- 훈련 데이터와 테스트 데이터로 구분하여 테스트 데이터 정확도를 구하시오\n",
    "- 종속변수가 문자열임에 유의\n",
    "- 최종 모델을 Best 모델로 간주하여, 최종 모델을 불러 예측하시오\n",
    "    - (ModelCheckpoint를 사용하지 않음)\n",
    "    - 독립변수: 60개. 각 특정 주파수 대의 누적 에너지\n",
    "    - 종속변수: M-금속, R-암석\n",
    "\n",
    "- https://datahub.io/machine-learning/sonar%23resource-sonar#resource-sonar_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\elice_python\\\\GAS_5\\\\pytest'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = 'D:\\elice_python\\GAS_5\\pytest'\n",
    "\n",
    "os.chdir(path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>attribute_6</th>\n",
       "      <th>attribute_7</th>\n",
       "      <th>attribute_8</th>\n",
       "      <th>attribute_9</th>\n",
       "      <th>attribute_10</th>\n",
       "      <th>...</th>\n",
       "      <th>attribute_52</th>\n",
       "      <th>attribute_53</th>\n",
       "      <th>attribute_54</th>\n",
       "      <th>attribute_55</th>\n",
       "      <th>attribute_56</th>\n",
       "      <th>attribute_57</th>\n",
       "      <th>attribute_58</th>\n",
       "      <th>attribute_59</th>\n",
       "      <th>attribute_60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_1  attribute_2  attribute_3  attribute_4  attribute_5  \\\n",
       "0         0.02       0.0371       0.0428       0.0207       0.0954   \n",
       "\n",
       "   attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...  \\\n",
       "0       0.0986       0.1539       0.1601       0.3109        0.2111  ...   \n",
       "\n",
       "   attribute_52  attribute_53  attribute_54  attribute_55  attribute_56  \\\n",
       "0        0.0027        0.0065        0.0159        0.0072        0.0167   \n",
       "\n",
       "   attribute_57  attribute_58  attribute_59  attribute_60  Class  \n",
       "0         0.018        0.0084         0.009        0.0032   Rock  \n",
       "\n",
       "[1 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sonar.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   attribute_1   208 non-null    float64\n",
      " 1   attribute_2   208 non-null    float64\n",
      " 2   attribute_3   208 non-null    float64\n",
      " 3   attribute_4   208 non-null    float64\n",
      " 4   attribute_5   208 non-null    float64\n",
      " 5   attribute_6   208 non-null    float64\n",
      " 6   attribute_7   208 non-null    float64\n",
      " 7   attribute_8   208 non-null    float64\n",
      " 8   attribute_9   208 non-null    float64\n",
      " 9   attribute_10  208 non-null    float64\n",
      " 10  attribute_11  208 non-null    float64\n",
      " 11  attribute_12  208 non-null    float64\n",
      " 12  attribute_13  208 non-null    float64\n",
      " 13  attribute_14  208 non-null    float64\n",
      " 14  attribute_15  208 non-null    float64\n",
      " 15  attribute_16  208 non-null    float64\n",
      " 16  attribute_17  208 non-null    float64\n",
      " 17  attribute_18  208 non-null    float64\n",
      " 18  attribute_19  208 non-null    float64\n",
      " 19  attribute_20  208 non-null    float64\n",
      " 20  attribute_21  208 non-null    float64\n",
      " 21  attribute_22  208 non-null    float64\n",
      " 22  attribute_23  208 non-null    float64\n",
      " 23  attribute_24  208 non-null    float64\n",
      " 24  attribute_25  208 non-null    float64\n",
      " 25  attribute_26  208 non-null    float64\n",
      " 26  attribute_27  208 non-null    float64\n",
      " 27  attribute_28  208 non-null    float64\n",
      " 28  attribute_29  208 non-null    float64\n",
      " 29  attribute_30  208 non-null    float64\n",
      " 30  attribute_31  208 non-null    float64\n",
      " 31  attribute_32  208 non-null    float64\n",
      " 32  attribute_33  208 non-null    float64\n",
      " 33  attribute_34  208 non-null    float64\n",
      " 34  attribute_35  208 non-null    float64\n",
      " 35  attribute_36  208 non-null    float64\n",
      " 36  attribute_37  208 non-null    float64\n",
      " 37  attribute_38  208 non-null    float64\n",
      " 38  attribute_39  208 non-null    float64\n",
      " 39  attribute_40  208 non-null    float64\n",
      " 40  attribute_41  208 non-null    float64\n",
      " 41  attribute_42  208 non-null    float64\n",
      " 42  attribute_43  208 non-null    float64\n",
      " 43  attribute_44  208 non-null    float64\n",
      " 44  attribute_45  208 non-null    float64\n",
      " 45  attribute_46  208 non-null    float64\n",
      " 46  attribute_47  208 non-null    float64\n",
      " 47  attribute_48  208 non-null    float64\n",
      " 48  attribute_49  208 non-null    float64\n",
      " 49  attribute_50  208 non-null    float64\n",
      " 50  attribute_51  208 non-null    float64\n",
      " 51  attribute_52  208 non-null    float64\n",
      " 52  attribute_53  208 non-null    float64\n",
      " 53  attribute_54  208 non-null    float64\n",
      " 54  attribute_55  208 non-null    float64\n",
      " 55  attribute_56  208 non-null    float64\n",
      " 56  attribute_57  208 non-null    float64\n",
      " 57  attribute_58  208 non-null    float64\n",
      " 58  attribute_59  208 non-null    float64\n",
      " 59  attribute_60  208 non-null    float64\n",
      " 60  Class         208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rock', 'Mine'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Class == 'Rock', 'Class'] = 0\n",
    "df.loc[df.Class == 'Mine', 'Class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((208, 60), (208,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1].astype('int32')\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import  Sequential\n",
    "from keras.layers import  Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input((60,)))\n",
    "model.add(Dense(180, activation='relu', input_shape = (60,)))\n",
    "model.add(Dense(90, activation = 'relu'))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 180)               10980     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 90)                16290     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                2730      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,321\n",
      "Trainable params: 30,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156, 60), (156,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 156 entries, 47 to 61\n",
      "Series name: Class\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "156 non-null    int32\n",
      "dtypes: int32(1)\n",
      "memory usage: 1.8 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 180)               10980     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 90)                16290     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                2730      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,321\n",
      "Trainable params: 30,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 1: val_loss improved from inf to 0.95648, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\sonar.keras\n",
      "1/1 [==============================] - 1s 557ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.9565 - val_acc: 0.6875\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1055 - acc: 0.9435\n",
      "Epoch 2: val_loss improved from 0.95648 to 0.77016, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\sonar.keras\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1055 - acc: 0.9435 - val_loss: 0.7702 - val_acc: 0.7812\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0235 - acc: 1.0000\n",
      "Epoch 3: val_loss did not improve from 0.77016\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.9563 - val_acc: 0.7500\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1176 - acc: 0.9194\n",
      "Epoch 4: val_loss did not improve from 0.77016\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1176 - acc: 0.9194 - val_loss: 0.8538 - val_acc: 0.7812\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0622 - acc: 1.0000\n",
      "Epoch 5: val_loss improved from 0.77016 to 0.74062, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\sonar.keras\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0622 - acc: 1.0000 - val_loss: 0.7406 - val_acc: 0.8125\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 6: val_loss did not improve from 0.74062\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.7547 - val_acc: 0.7812\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 7: val_loss did not improve from 0.74062\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.8355 - val_acc: 0.7500\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0543 - acc: 0.9839\n",
      "Epoch 8: val_loss did not improve from 0.74062\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0543 - acc: 0.9839 - val_loss: 0.8492 - val_acc: 0.7188\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0584 - acc: 0.9839\n",
      "Epoch 9: val_loss did not improve from 0.74062\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0584 - acc: 0.9839 - val_loss: 0.7881 - val_acc: 0.7188\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0339 - acc: 1.0000\n",
      "Epoch 10: val_loss improved from 0.74062 to 0.74011, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\sonar.keras\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0339 - acc: 1.0000 - val_loss: 0.7401 - val_acc: 0.7812\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0183 - acc: 1.0000\n",
      "Epoch 11: val_loss improved from 0.74011 to 0.73980, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\sonar.keras\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.7398 - val_acc: 0.8125\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 12: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.7715 - val_acc: 0.8438\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0288 - acc: 1.0000\n",
      "Epoch 13: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0288 - acc: 1.0000 - val_loss: 0.7972 - val_acc: 0.8125\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0377 - acc: 1.0000\n",
      "Epoch 14: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0377 - acc: 1.0000 - val_loss: 0.7923 - val_acc: 0.8125\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0342 - acc: 1.0000\n",
      "Epoch 15: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0342 - acc: 1.0000 - val_loss: 0.7678 - val_acc: 0.8125\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 16: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0237 - acc: 1.0000 - val_loss: 0.7514 - val_acc: 0.8125\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 17: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.7577 - val_acc: 0.7812\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 18: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.7815 - val_acc: 0.7812\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0205 - acc: 1.0000\n",
      "Epoch 19: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.8039 - val_acc: 0.7188\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 20: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.8064 - val_acc: 0.7188\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0247 - acc: 1.0000\n",
      "Epoch 21: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.7910 - val_acc: 0.7812\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 22: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.7750 - val_acc: 0.7812\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 23: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.7699 - val_acc: 0.7812\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 24: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.7765 - val_acc: 0.8125\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 25: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.7871 - val_acc: 0.8125\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 26: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0179 - acc: 1.0000 - val_loss: 0.7929 - val_acc: 0.8125\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 27: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.7908 - val_acc: 0.8125\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 28: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.7849 - val_acc: 0.8125\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 29: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.7826 - val_acc: 0.7812\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 30: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.7864 - val_acc: 0.7812\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 31: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.7946 - val_acc: 0.7812\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 32: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.8020 - val_acc: 0.7812\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 33: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.8036 - val_acc: 0.7812\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 34: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.8005 - val_acc: 0.7812\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 35: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.7967 - val_acc: 0.7812\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 36: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.7962 - val_acc: 0.7812\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 37: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.7993 - val_acc: 0.7812\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 38: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.8035 - val_acc: 0.7812\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.8061 - val_acc: 0.8125\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0124 - acc: 1.0000\n",
      "Epoch 40: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.8065 - val_acc: 0.7812\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0119 - acc: 1.0000\n",
      "Epoch 41: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.8061 - val_acc: 0.7812\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 42: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.8065 - val_acc: 0.7812\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 43: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.8086 - val_acc: 0.7812\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 44: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.8118 - val_acc: 0.7812\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 45: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.8151 - val_acc: 0.7812\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 46: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.8167 - val_acc: 0.7812\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 47: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.8167 - val_acc: 0.7812\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 48: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.8169 - val_acc: 0.7812\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 49: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.8182 - val_acc: 0.7812\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 50: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.8202 - val_acc: 0.7812\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 51: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.8230 - val_acc: 0.7812\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 52: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.8250 - val_acc: 0.7812\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 53: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.8263 - val_acc: 0.7812\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 54: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.8272 - val_acc: 0.7812\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 55: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.8284 - val_acc: 0.7812\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 56: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.8306 - val_acc: 0.7812\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 57: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.8331 - val_acc: 0.7812\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 58: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.8358 - val_acc: 0.7812\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 59: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.8380 - val_acc: 0.7812\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 60: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.8399 - val_acc: 0.7812\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 61: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.8423 - val_acc: 0.7812\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 62: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.8444 - val_acc: 0.7812\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 63: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.8474 - val_acc: 0.7812\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 64: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.8494 - val_acc: 0.7812\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 65: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.8512 - val_acc: 0.7812\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 66: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.8530 - val_acc: 0.7812\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 67: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.8546 - val_acc: 0.7812\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 68: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.8565 - val_acc: 0.7812\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 69: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.8582 - val_acc: 0.7812\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 70: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.8600 - val_acc: 0.7812\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 71: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.8615 - val_acc: 0.7812\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 72: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.8632 - val_acc: 0.7812\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 73: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.8652 - val_acc: 0.7812\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 74: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.8676 - val_acc: 0.7812\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 75: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.8697 - val_acc: 0.7812\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 76: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.8722 - val_acc: 0.7812\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 77: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.8742 - val_acc: 0.7812\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 78: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.8760 - val_acc: 0.7812\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 79: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.8780 - val_acc: 0.7812\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 80: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.8805 - val_acc: 0.7812\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 81: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.8828 - val_acc: 0.7812\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 82: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.8854 - val_acc: 0.7812\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 83: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.8881 - val_acc: 0.7812\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 84: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.8907 - val_acc: 0.7812\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 85: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.8932 - val_acc: 0.7812\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 86: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.8957 - val_acc: 0.7812\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 87: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.8978 - val_acc: 0.7812\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 88: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.9001 - val_acc: 0.7812\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 89: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.9023 - val_acc: 0.7812\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 90: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.9040 - val_acc: 0.7812\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 91: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.9067 - val_acc: 0.7812\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 92: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.9095 - val_acc: 0.7812\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 93: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.9131 - val_acc: 0.7812\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 94: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.9157 - val_acc: 0.7812\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 95: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.9175 - val_acc: 0.7812\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 96: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.9190 - val_acc: 0.7812\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 97: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.9199 - val_acc: 0.7812\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 98: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.9206 - val_acc: 0.7812\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 99: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.9211 - val_acc: 0.7812\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 100: val_loss did not improve from 0.73980\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.9214 - val_acc: 0.7812\n"
     ]
    }
   ],
   "source": [
    "model_dir = os.path.join(path,'models')\n",
    "modelpath = os.path.join(model_dir, 'sonar.keras')\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=modelpath,\n",
    "    monitor= 'val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only= True\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=100, \n",
    "                    batch_size=156,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[checkpointer]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5100 - acc: 0.8462\n"
     ]
    }
   ],
   "source": [
    "evaluation = loaded_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5100235342979431, 0.8461538553237915]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "- credit_card_clients.xls 파일은 30,000개의 행과 24개의 속성을 가지고 있다\n",
    "- 이중 default payment next month 컬럼이 종속변수로 연체일 경우 1, 정상납부일 경우 0이다\n",
    "- pd.read_excel()로 읽고 연체 여부를 예측하는 모델을 만드시오\n",
    "- 이전 모델보다 좋은 모델일 때만 저장하여 Best 모델을 불러 예측하시오\n",
    "- 훈련데이터와 validation 데이터에 대한 정확도 및 손실값 그래프를 그리시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...          0          0          0         0       689         0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('credit_card_clients.csv', header=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count  Dtype\n",
      "---  ------                      --------------  -----\n",
      " 0   ID                          30000 non-null  int64\n",
      " 1   LIMIT_BAL                   30000 non-null  int64\n",
      " 2   SEX                         30000 non-null  int64\n",
      " 3   EDUCATION                   30000 non-null  int64\n",
      " 4   MARRIAGE                    30000 non-null  int64\n",
      " 5   AGE                         30000 non-null  int64\n",
      " 6   PAY_0                       30000 non-null  int64\n",
      " 7   PAY_2                       30000 non-null  int64\n",
      " 8   PAY_3                       30000 non-null  int64\n",
      " 9   PAY_4                       30000 non-null  int64\n",
      " 10  PAY_5                       30000 non-null  int64\n",
      " 11  PAY_6                       30000 non-null  int64\n",
      " 12  BILL_AMT1                   30000 non-null  int64\n",
      " 13  BILL_AMT2                   30000 non-null  int64\n",
      " 14  BILL_AMT3                   30000 non-null  int64\n",
      " 15  BILL_AMT4                   30000 non-null  int64\n",
      " 16  BILL_AMT5                   30000 non-null  int64\n",
      " 17  BILL_AMT6                   30000 non-null  int64\n",
      " 18  PAY_AMT1                    30000 non-null  int64\n",
      " 19  PAY_AMT2                    30000 non-null  int64\n",
      " 20  PAY_AMT3                    30000 non-null  int64\n",
      " 21  PAY_AMT4                    30000 non-null  int64\n",
      " 22  PAY_AMT5                    30000 non-null  int64\n",
      " 23  PAY_AMT6                    30000 non-null  int64\n",
      " 24  default payment next month  30000 non-null  int64\n",
      "dtypes: int64(25)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,-1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import  Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input((24,)))\n",
    "model.add(Dense(72, activation='relu', input_shape = (25,)))\n",
    "model.add(Dense(40, activation = 'relu'))\n",
    "model.add(Dense(20, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 486.0770 - acc: 0.5811 \n",
      "Epoch 1: val_loss improved from inf to 40.82116, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_1-40.8212.keras\n",
      "18/18 [==============================] - 1s 17ms/step - loss: 381.0067 - acc: 0.6088 - val_loss: 40.8212 - val_acc: 0.7107\n",
      "Epoch 2/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 25.7353 - acc: 0.7327\n",
      "Epoch 2: val_loss improved from 40.82116 to 7.73621, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_2-7.7362.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 21.2233 - acc: 0.7410 - val_loss: 7.7362 - val_acc: 0.7558\n",
      "Epoch 3/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 5.8189 - acc: 0.7655\n",
      "Epoch 3: val_loss improved from 7.73621 to 2.68804, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_3-2.6880.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 4.9392 - acc: 0.7693 - val_loss: 2.6880 - val_acc: 0.7651\n",
      "Epoch 4/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 2.6127 - acc: 0.7748\n",
      "Epoch 4: val_loss improved from 2.68804 to 2.16281, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_4-2.1628.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2.4522 - acc: 0.7759 - val_loss: 2.1628 - val_acc: 0.7671\n",
      "Epoch 5/200\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 1.8587 - acc: 0.7755\n",
      "Epoch 5: val_loss improved from 2.16281 to 1.79709, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_5-1.7971.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.7374 - acc: 0.7776 - val_loss: 1.7971 - val_acc: 0.7689\n",
      "Epoch 6/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 1.5367 - acc: 0.7816\n",
      "Epoch 6: val_loss improved from 1.79709 to 1.69448, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_6-1.6945.keras\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.5052 - acc: 0.7786 - val_loss: 1.6945 - val_acc: 0.7673\n",
      "Epoch 7/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 1.3026 - acc: 0.7809\n",
      "Epoch 7: val_loss did not improve from 1.69448\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.2653 - acc: 0.7789 - val_loss: 1.6988 - val_acc: 0.7667\n",
      "Epoch 8/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 1.1807 - acc: 0.7827\n",
      "Epoch 8: val_loss did not improve from 1.69448\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.1716 - acc: 0.7786 - val_loss: 1.7041 - val_acc: 0.7669\n",
      "Epoch 9/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 1.0719 - acc: 0.7799\n",
      "Epoch 9: val_loss did not improve from 1.69448\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.1073 - acc: 0.7794 - val_loss: 1.9201 - val_acc: 0.7676\n",
      "Epoch 10/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.9962 - acc: 0.7785\n",
      "Epoch 10: val_loss did not improve from 1.69448\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0565 - acc: 0.7798 - val_loss: 2.0495 - val_acc: 0.7676\n",
      "Epoch 11/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 1.1267 - acc: 0.7797\n",
      "Epoch 11: val_loss did not improve from 1.69448\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0353 - acc: 0.7796 - val_loss: 1.9900 - val_acc: 0.7676\n",
      "Epoch 12/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.9826 - acc: 0.7819\n",
      "Epoch 12: val_loss did not improve from 1.69448\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9933 - acc: 0.7794 - val_loss: 1.9204 - val_acc: 0.7680\n",
      "Epoch 13/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.9528 - acc: 0.7792\n",
      "Epoch 13: val_loss did not improve from 1.69448\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9681 - acc: 0.7794 - val_loss: 1.9527 - val_acc: 0.7680\n",
      "Epoch 14/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.9335 - acc: 0.7786\n",
      "Epoch 14: val_loss did not improve from 1.69448\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9128 - acc: 0.7793 - val_loss: 1.7575 - val_acc: 0.7684\n",
      "Epoch 15/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.9249 - acc: 0.7777\n",
      "Epoch 15: val_loss improved from 1.69448 to 1.57412, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_15-1.5741.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.8725 - acc: 0.7794 - val_loss: 1.5741 - val_acc: 0.7689\n",
      "Epoch 16/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.8266 - acc: 0.7783\n",
      "Epoch 16: val_loss did not improve from 1.57412\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.8559 - acc: 0.7798 - val_loss: 1.6473 - val_acc: 0.7684\n",
      "Epoch 17/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.7855 - acc: 0.7836\n",
      "Epoch 17: val_loss did not improve from 1.57412\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.8128 - acc: 0.7798 - val_loss: 1.5918 - val_acc: 0.7678\n",
      "Epoch 18/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.8127 - acc: 0.7819\n",
      "Epoch 18: val_loss did not improve from 1.57412\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.8114 - acc: 0.7798 - val_loss: 1.9423 - val_acc: 0.7687\n",
      "Epoch 19/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.7641 - acc: 0.7822\n",
      "Epoch 19: val_loss did not improve from 1.57412\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.7777 - acc: 0.7802 - val_loss: 1.7667 - val_acc: 0.7684\n",
      "Epoch 20/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.7530 - acc: 0.7778\n",
      "Epoch 20: val_loss improved from 1.57412 to 1.56229, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_20-1.5623.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.7579 - acc: 0.7802 - val_loss: 1.5623 - val_acc: 0.7684\n",
      "Epoch 21/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.7547 - acc: 0.7780\n",
      "Epoch 21: val_loss improved from 1.56229 to 1.33664, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_21-1.3366.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.7589 - acc: 0.7802 - val_loss: 1.3366 - val_acc: 0.7687\n",
      "Epoch 22/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.7620 - acc: 0.7805\n",
      "Epoch 22: val_loss improved from 1.33664 to 1.06287, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_22-1.0629.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.7489 - acc: 0.7804 - val_loss: 1.0629 - val_acc: 0.7684\n",
      "Epoch 23/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.7481 - acc: 0.7797\n",
      "Epoch 23: val_loss improved from 1.06287 to 1.02500, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_23-1.0250.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.7471 - acc: 0.7803 - val_loss: 1.0250 - val_acc: 0.7680\n",
      "Epoch 24/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.7393 - acc: 0.7808\n",
      "Epoch 24: val_loss improved from 1.02500 to 0.96424, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_24-0.9642.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.7265 - acc: 0.7803 - val_loss: 0.9642 - val_acc: 0.7687\n",
      "Epoch 25/200\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.7229 - acc: 0.7834\n",
      "Epoch 25: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.7247 - acc: 0.7801 - val_loss: 1.3425 - val_acc: 0.7684\n",
      "Epoch 26/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.7224 - acc: 0.7827\n",
      "Epoch 26: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.7113 - acc: 0.7803 - val_loss: 1.2826 - val_acc: 0.7689\n",
      "Epoch 27/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.7002 - acc: 0.7813\n",
      "Epoch 27: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.7013 - acc: 0.7807 - val_loss: 1.2462 - val_acc: 0.7684\n",
      "Epoch 28/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.7007 - acc: 0.7802\n",
      "Epoch 28: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6853 - acc: 0.7804 - val_loss: 1.2388 - val_acc: 0.7684\n",
      "Epoch 29/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.6749 - acc: 0.7772\n",
      "Epoch 29: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6754 - acc: 0.7805 - val_loss: 1.2377 - val_acc: 0.7689\n",
      "Epoch 30/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.6497 - acc: 0.7802\n",
      "Epoch 30: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6676 - acc: 0.7807 - val_loss: 1.2343 - val_acc: 0.7689\n",
      "Epoch 31/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.6506 - acc: 0.7815\n",
      "Epoch 31: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6596 - acc: 0.7809 - val_loss: 1.2038 - val_acc: 0.7689\n",
      "Epoch 32/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.6573 - acc: 0.7817\n",
      "Epoch 32: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6560 - acc: 0.7808 - val_loss: 1.1955 - val_acc: 0.7691\n",
      "Epoch 33/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.6398 - acc: 0.7791\n",
      "Epoch 33: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6489 - acc: 0.7809 - val_loss: 1.2358 - val_acc: 0.7691\n",
      "Epoch 34/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.6262 - acc: 0.7824\n",
      "Epoch 34: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6437 - acc: 0.7809 - val_loss: 1.1925 - val_acc: 0.7696\n",
      "Epoch 35/200\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.6175 - acc: 0.7830\n",
      "Epoch 35: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6422 - acc: 0.7808 - val_loss: 1.1785 - val_acc: 0.7696\n",
      "Epoch 36/200\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.6728 - acc: 0.7826\n",
      "Epoch 36: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6477 - acc: 0.7804 - val_loss: 1.1956 - val_acc: 0.7696\n",
      "Epoch 37/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.6302 - acc: 0.7807\n",
      "Epoch 37: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6321 - acc: 0.7809 - val_loss: 1.1715 - val_acc: 0.7696\n",
      "Epoch 38/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.6390 - acc: 0.7822\n",
      "Epoch 38: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6313 - acc: 0.7809 - val_loss: 1.1207 - val_acc: 0.7693\n",
      "Epoch 39/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.6176 - acc: 0.7789\n",
      "Epoch 39: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6180 - acc: 0.7808 - val_loss: 1.1096 - val_acc: 0.7693\n",
      "Epoch 40/200\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.5942 - acc: 0.7819\n",
      "Epoch 40: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6089 - acc: 0.7811 - val_loss: 1.1228 - val_acc: 0.7691\n",
      "Epoch 41/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5971 - acc: 0.7816\n",
      "Epoch 41: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6085 - acc: 0.7811 - val_loss: 1.0883 - val_acc: 0.7696\n",
      "Epoch 42/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.6026 - acc: 0.7809\n",
      "Epoch 42: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6129 - acc: 0.7808 - val_loss: 1.1583 - val_acc: 0.7698\n",
      "Epoch 43/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5990 - acc: 0.7840\n",
      "Epoch 43: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6183 - acc: 0.7808 - val_loss: 1.2042 - val_acc: 0.7696\n",
      "Epoch 44/200\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.5892 - acc: 0.7794\n",
      "Epoch 44: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6010 - acc: 0.7811 - val_loss: 1.1545 - val_acc: 0.7691\n",
      "Epoch 45/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.6021 - acc: 0.7820\n",
      "Epoch 45: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5966 - acc: 0.7812 - val_loss: 1.2088 - val_acc: 0.7693\n",
      "Epoch 46/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5912 - acc: 0.7800\n",
      "Epoch 46: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5911 - acc: 0.7813 - val_loss: 1.1862 - val_acc: 0.7693\n",
      "Epoch 47/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5983 - acc: 0.7809\n",
      "Epoch 47: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5901 - acc: 0.7809 - val_loss: 1.1993 - val_acc: 0.7696\n",
      "Epoch 48/200\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.5908 - acc: 0.7808\n",
      "Epoch 48: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5986 - acc: 0.7809 - val_loss: 1.0397 - val_acc: 0.7696\n",
      "Epoch 49/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.6652 - acc: 0.7834\n",
      "Epoch 49: val_loss did not improve from 0.96424\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.7722 - acc: 0.7809 - val_loss: 1.7339 - val_acc: 0.7702\n",
      "Epoch 50/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 2.3130 - acc: 0.7811 \n",
      "Epoch 50: val_loss improved from 0.96424 to 0.71397, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_50-0.7140.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.8646 - acc: 0.7802 - val_loss: 0.7140 - val_acc: 0.7702\n",
      "Epoch 51/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5772 - acc: 0.7784\n",
      "Epoch 51: val_loss improved from 0.71397 to 0.59367, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_51-0.5937.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.8246 - acc: 0.7808 - val_loss: 0.5937 - val_acc: 0.7700\n",
      "Epoch 52/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.6420 - acc: 0.7814\n",
      "Epoch 52: val_loss did not improve from 0.59367\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6444 - acc: 0.7805 - val_loss: 0.5953 - val_acc: 0.7709\n",
      "Epoch 53/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5811 - acc: 0.7815\n",
      "Epoch 53: val_loss improved from 0.59367 to 0.56185, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_53-0.5619.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5800 - acc: 0.7808 - val_loss: 0.5619 - val_acc: 0.7709\n",
      "Epoch 54/200\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.5740 - acc: 0.7821\n",
      "Epoch 54: val_loss improved from 0.56185 to 0.56001, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_54-0.5600.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5738 - acc: 0.7808 - val_loss: 0.5600 - val_acc: 0.7709\n",
      "Epoch 55/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5619 - acc: 0.7822\n",
      "Epoch 55: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5645 - acc: 0.7808 - val_loss: 0.6471 - val_acc: 0.7704\n",
      "Epoch 56/200\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5680 - acc: 0.7807\n",
      "Epoch 56: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5658 - acc: 0.7809 - val_loss: 0.6105 - val_acc: 0.7704\n",
      "Epoch 57/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5575 - acc: 0.7812\n",
      "Epoch 57: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5563 - acc: 0.7812 - val_loss: 0.6031 - val_acc: 0.7709\n",
      "Epoch 58/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5558 - acc: 0.7819\n",
      "Epoch 58: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5547 - acc: 0.7812 - val_loss: 0.5988 - val_acc: 0.7709\n",
      "Epoch 59/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5455 - acc: 0.7829\n",
      "Epoch 59: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5525 - acc: 0.7812 - val_loss: 0.5928 - val_acc: 0.7709\n",
      "Epoch 60/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5513 - acc: 0.7816\n",
      "Epoch 60: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5503 - acc: 0.7812 - val_loss: 0.5849 - val_acc: 0.7709\n",
      "Epoch 61/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5437 - acc: 0.7829\n",
      "Epoch 61: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5484 - acc: 0.7813 - val_loss: 0.5810 - val_acc: 0.7709\n",
      "Epoch 62/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5495 - acc: 0.7792\n",
      "Epoch 62: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5468 - acc: 0.7813 - val_loss: 0.5794 - val_acc: 0.7709\n",
      "Epoch 63/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5480 - acc: 0.7791\n",
      "Epoch 63: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5458 - acc: 0.7811 - val_loss: 0.5789 - val_acc: 0.7709\n",
      "Epoch 64/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5440 - acc: 0.7841\n",
      "Epoch 64: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5451 - acc: 0.7813 - val_loss: 0.5754 - val_acc: 0.7709\n",
      "Epoch 65/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5435 - acc: 0.7822\n",
      "Epoch 65: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5435 - acc: 0.7813 - val_loss: 0.5720 - val_acc: 0.7709\n",
      "Epoch 66/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5434 - acc: 0.7812\n",
      "Epoch 66: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5427 - acc: 0.7813 - val_loss: 0.5697 - val_acc: 0.7709\n",
      "Epoch 67/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5407 - acc: 0.7833\n",
      "Epoch 67: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5417 - acc: 0.7813 - val_loss: 0.5692 - val_acc: 0.7709\n",
      "Epoch 68/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5411 - acc: 0.7818\n",
      "Epoch 68: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5411 - acc: 0.7813 - val_loss: 0.5702 - val_acc: 0.7709\n",
      "Epoch 69/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5395 - acc: 0.7806\n",
      "Epoch 69: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5404 - acc: 0.7812 - val_loss: 0.5684 - val_acc: 0.7709\n",
      "Epoch 70/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5362 - acc: 0.7836\n",
      "Epoch 70: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5395 - acc: 0.7813 - val_loss: 0.5684 - val_acc: 0.7709\n",
      "Epoch 71/200\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.5382 - acc: 0.7824\n",
      "Epoch 71: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5392 - acc: 0.7813 - val_loss: 0.5707 - val_acc: 0.7709\n",
      "Epoch 72/200\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5386 - acc: 0.7808\n",
      "Epoch 72: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5379 - acc: 0.7813 - val_loss: 0.5705 - val_acc: 0.7709\n",
      "Epoch 73/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5385 - acc: 0.7804\n",
      "Epoch 73: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5374 - acc: 0.7813 - val_loss: 0.5692 - val_acc: 0.7709\n",
      "Epoch 74/200\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5381 - acc: 0.7799\n",
      "Epoch 74: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5367 - acc: 0.7813 - val_loss: 0.5703 - val_acc: 0.7709\n",
      "Epoch 75/200\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5362 - acc: 0.7814\n",
      "Epoch 75: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5362 - acc: 0.7813 - val_loss: 0.5685 - val_acc: 0.7709\n",
      "Epoch 76/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5348 - acc: 0.7826\n",
      "Epoch 76: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5357 - acc: 0.7813 - val_loss: 0.5672 - val_acc: 0.7709\n",
      "Epoch 77/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5356 - acc: 0.7808\n",
      "Epoch 77: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5349 - acc: 0.7813 - val_loss: 0.5667 - val_acc: 0.7709\n",
      "Epoch 78/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5343 - acc: 0.7809\n",
      "Epoch 78: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5341 - acc: 0.7813 - val_loss: 0.5676 - val_acc: 0.7709\n",
      "Epoch 79/200\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.5355 - acc: 0.7804\n",
      "Epoch 79: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5342 - acc: 0.7813 - val_loss: 0.5666 - val_acc: 0.7709\n",
      "Epoch 80/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5354 - acc: 0.7792\n",
      "Epoch 80: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5337 - acc: 0.7813 - val_loss: 0.5659 - val_acc: 0.7709\n",
      "Epoch 81/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5350 - acc: 0.7791\n",
      "Epoch 81: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5327 - acc: 0.7813 - val_loss: 0.5663 - val_acc: 0.7709\n",
      "Epoch 82/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5351 - acc: 0.7789\n",
      "Epoch 82: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5326 - acc: 0.7813 - val_loss: 0.5648 - val_acc: 0.7709\n",
      "Epoch 83/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5341 - acc: 0.7790\n",
      "Epoch 83: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5318 - acc: 0.7813 - val_loss: 0.5651 - val_acc: 0.7709\n",
      "Epoch 84/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5302 - acc: 0.7828\n",
      "Epoch 84: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5314 - acc: 0.7814 - val_loss: 0.5645 - val_acc: 0.7709\n",
      "Epoch 85/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5326 - acc: 0.7799\n",
      "Epoch 85: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5311 - acc: 0.7814 - val_loss: 0.5652 - val_acc: 0.7709\n",
      "Epoch 86/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5317 - acc: 0.7805\n",
      "Epoch 86: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5310 - acc: 0.7813 - val_loss: 0.5639 - val_acc: 0.7709\n",
      "Epoch 87/200\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5308 - acc: 0.7811\n",
      "Epoch 87: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5304 - acc: 0.7814 - val_loss: 0.5643 - val_acc: 0.7709\n",
      "Epoch 88/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5293 - acc: 0.7823\n",
      "Epoch 88: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5303 - acc: 0.7813 - val_loss: 0.5629 - val_acc: 0.7709\n",
      "Epoch 89/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5274 - acc: 0.7839\n",
      "Epoch 89: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5302 - acc: 0.7813 - val_loss: 0.5604 - val_acc: 0.7709\n",
      "Epoch 90/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5291 - acc: 0.7819\n",
      "Epoch 90: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5296 - acc: 0.7814 - val_loss: 0.5611 - val_acc: 0.7709\n",
      "Epoch 91/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5285 - acc: 0.7821\n",
      "Epoch 91: val_loss did not improve from 0.56001\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5293 - acc: 0.7813 - val_loss: 0.5605 - val_acc: 0.7709\n",
      "Epoch 92/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5310 - acc: 0.7796\n",
      "Epoch 92: val_loss improved from 0.56001 to 0.55988, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_92-0.5599.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5291 - acc: 0.7814 - val_loss: 0.5599 - val_acc: 0.7709\n",
      "Epoch 93/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5253 - acc: 0.7848\n",
      "Epoch 93: val_loss did not improve from 0.55988\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5289 - acc: 0.7813 - val_loss: 0.5606 - val_acc: 0.7709\n",
      "Epoch 94/200\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5293 - acc: 0.7808\n",
      "Epoch 94: val_loss did not improve from 0.55988\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5286 - acc: 0.7814 - val_loss: 0.5600 - val_acc: 0.7709\n",
      "Epoch 95/200\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5284 - acc: 0.7813\n",
      "Epoch 95: val_loss improved from 0.55988 to 0.55907, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_95-0.5591.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5284 - acc: 0.7813 - val_loss: 0.5591 - val_acc: 0.7709\n",
      "Epoch 96/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5294 - acc: 0.7804\n",
      "Epoch 96: val_loss improved from 0.55907 to 0.55890, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_96-0.5589.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5282 - acc: 0.7814 - val_loss: 0.5589 - val_acc: 0.7709\n",
      "Epoch 97/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5301 - acc: 0.7794\n",
      "Epoch 97: val_loss improved from 0.55890 to 0.55874, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_97-0.5587.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5280 - acc: 0.7814 - val_loss: 0.5587 - val_acc: 0.7709\n",
      "Epoch 98/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5301 - acc: 0.7792\n",
      "Epoch 98: val_loss did not improve from 0.55874\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5278 - acc: 0.7814 - val_loss: 0.5590 - val_acc: 0.7709\n",
      "Epoch 99/200\n",
      "11/18 [=================>............] - ETA: 0s - loss: 0.5319 - acc: 0.7775\n",
      "Epoch 99: val_loss improved from 0.55874 to 0.55842, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_99-0.5584.keras\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5276 - acc: 0.7814 - val_loss: 0.5584 - val_acc: 0.7709\n",
      "Epoch 100/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5268 - acc: 0.7819\n",
      "Epoch 100: val_loss improved from 0.55842 to 0.55830, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_100-0.5583.keras\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5274 - acc: 0.7814 - val_loss: 0.5583 - val_acc: 0.7709\n",
      "Epoch 101/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5289 - acc: 0.7800\n",
      "Epoch 101: val_loss improved from 0.55830 to 0.55819, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_101-0.5582.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5273 - acc: 0.7814 - val_loss: 0.5582 - val_acc: 0.7709\n",
      "Epoch 102/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5257 - acc: 0.7828\n",
      "Epoch 102: val_loss improved from 0.55819 to 0.55809, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_102-0.5581.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5271 - acc: 0.7814 - val_loss: 0.5581 - val_acc: 0.7709\n",
      "Epoch 103/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5266 - acc: 0.7818\n",
      "Epoch 103: val_loss improved from 0.55809 to 0.55800, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_103-0.5580.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5270 - acc: 0.7814 - val_loss: 0.5580 - val_acc: 0.7709\n",
      "Epoch 104/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5293 - acc: 0.7791\n",
      "Epoch 104: val_loss improved from 0.55800 to 0.55791, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_104-0.5579.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5268 - acc: 0.7814 - val_loss: 0.5579 - val_acc: 0.7709\n",
      "Epoch 105/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5259 - acc: 0.7822\n",
      "Epoch 105: val_loss improved from 0.55791 to 0.55782, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_105-0.5578.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5267 - acc: 0.7814 - val_loss: 0.5578 - val_acc: 0.7709\n",
      "Epoch 106/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5253 - acc: 0.7825\n",
      "Epoch 106: val_loss improved from 0.55782 to 0.55774, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_106-0.5577.keras\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5266 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 107/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5281 - acc: 0.7799\n",
      "Epoch 107: val_loss improved from 0.55774 to 0.55767, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_107-0.5577.keras\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5264 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 108/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5264 - acc: 0.7814\n",
      "Epoch 108: val_loss improved from 0.55767 to 0.55761, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_108-0.5576.keras\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5263 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 109/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5261 - acc: 0.7814\n",
      "Epoch 109: val_loss improved from 0.55761 to 0.55755, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_109-0.5575.keras\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5262 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 110/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5279 - acc: 0.7798\n",
      "Epoch 110: val_loss improved from 0.55755 to 0.55749, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_110-0.5575.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5261 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 111/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5232 - acc: 0.7838\n",
      "Epoch 111: val_loss improved from 0.55749 to 0.55744, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_111-0.5574.keras\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5260 - acc: 0.7814 - val_loss: 0.5574 - val_acc: 0.7709\n",
      "Epoch 112/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5286 - acc: 0.7790\n",
      "Epoch 112: val_loss improved from 0.55744 to 0.55739, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_112-0.5574.keras\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5259 - acc: 0.7814 - val_loss: 0.5574 - val_acc: 0.7709\n",
      "Epoch 113/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5256 - acc: 0.7816\n",
      "Epoch 113: val_loss improved from 0.55739 to 0.55734, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_113-0.5573.keras\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5259 - acc: 0.7814 - val_loss: 0.5573 - val_acc: 0.7709\n",
      "Epoch 114/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5278 - acc: 0.7797\n",
      "Epoch 114: val_loss improved from 0.55734 to 0.55730, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_114-0.5573.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5258 - acc: 0.7814 - val_loss: 0.5573 - val_acc: 0.7709\n",
      "Epoch 115/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5262 - acc: 0.7809\n",
      "Epoch 115: val_loss improved from 0.55730 to 0.55726, saving model to D:\\elice_python\\GAS_5\\pytest\\models\\credit_115-0.5573.keras\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5257 - acc: 0.7814 - val_loss: 0.5573 - val_acc: 0.7709\n",
      "Epoch 116/200\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.5248 - acc: 0.7821\n",
      "Epoch 116: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5256 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 117/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5261 - acc: 0.7809\n",
      "Epoch 117: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5255 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 118/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5271 - acc: 0.7801\n",
      "Epoch 118: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5255 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 119/200\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5261 - acc: 0.7809\n",
      "Epoch 119: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5254 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 120/200\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5250 - acc: 0.7818\n",
      "Epoch 120: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5254 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 121/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5260 - acc: 0.7809\n",
      "Epoch 121: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5253 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 122/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5241 - acc: 0.7823\n",
      "Epoch 122: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5253 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 123/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5245 - acc: 0.7819\n",
      "Epoch 123: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5252 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 124/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5238 - acc: 0.7825\n",
      "Epoch 124: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5252 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 125/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5255 - acc: 0.7810\n",
      "Epoch 125: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5251 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 126/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5236 - acc: 0.7826\n",
      "Epoch 126: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5251 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 127/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5226 - acc: 0.7834\n",
      "Epoch 127: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5250 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 128/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5293 - acc: 0.7778\n",
      "Epoch 128: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5250 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 129/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5221 - acc: 0.7838\n",
      "Epoch 129: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5250 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 130/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5248 - acc: 0.7816\n",
      "Epoch 130: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5250 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 131/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5264 - acc: 0.7801\n",
      "Epoch 131: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5249 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 132/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5256 - acc: 0.7807\n",
      "Epoch 132: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5249 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 133/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5245 - acc: 0.7817\n",
      "Epoch 133: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5249 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 134/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5255 - acc: 0.7808\n",
      "Epoch 134: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5248 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 135/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5290 - acc: 0.7780\n",
      "Epoch 135: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5248 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 136/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5244 - acc: 0.7817\n",
      "Epoch 136: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5248 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 137/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5251 - acc: 0.7812\n",
      "Epoch 137: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5248 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 138/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5277 - acc: 0.7790\n",
      "Epoch 138: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5248 - acc: 0.7814 - val_loss: 0.5579 - val_acc: 0.7709\n",
      "Epoch 139/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5222 - acc: 0.7835\n",
      "Epoch 139: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5248 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 140/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5224 - acc: 0.7833\n",
      "Epoch 140: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5247 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 141/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5253 - acc: 0.7809\n",
      "Epoch 141: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5247 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 142/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5248 - acc: 0.7813\n",
      "Epoch 142: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5247 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 143/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5254 - acc: 0.7808\n",
      "Epoch 143: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5247 - acc: 0.7814 - val_loss: 0.5579 - val_acc: 0.7709\n",
      "Epoch 144/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5211 - acc: 0.7843\n",
      "Epoch 144: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5247 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 145/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5268 - acc: 0.7797\n",
      "Epoch 145: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5247 - acc: 0.7814 - val_loss: 0.5575 - val_acc: 0.7709\n",
      "Epoch 146/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5268 - acc: 0.7797\n",
      "Epoch 146: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5247 - acc: 0.7814 - val_loss: 0.5579 - val_acc: 0.7709\n",
      "Epoch 147/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5208 - acc: 0.7846\n",
      "Epoch 147: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5247 - acc: 0.7814 - val_loss: 0.5579 - val_acc: 0.7709\n",
      "Epoch 148/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5267 - acc: 0.7797\n",
      "Epoch 148: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 149/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5265 - acc: 0.7799\n",
      "Epoch 149: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 150/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5269 - acc: 0.7795\n",
      "Epoch 150: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 151/200\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5254 - acc: 0.7808\n",
      "Epoch 151: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 152/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5262 - acc: 0.7801\n",
      "Epoch 152: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 153/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5235 - acc: 0.7823\n",
      "Epoch 153: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 154/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5253 - acc: 0.7808\n",
      "Epoch 154: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 155/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5205 - acc: 0.7847\n",
      "Epoch 155: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 156/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5256 - acc: 0.7806\n",
      "Epoch 156: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 157/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5257 - acc: 0.7805\n",
      "Epoch 157: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 158/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5267 - acc: 0.7797\n",
      "Epoch 158: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5576 - val_acc: 0.7709\n",
      "Epoch 159/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5211 - acc: 0.7842\n",
      "Epoch 159: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 160/200\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5268 - acc: 0.7796\n",
      "Epoch 160: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 161/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5241 - acc: 0.7817\n",
      "Epoch 161: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 162/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5187 - acc: 0.7861\n",
      "Epoch 162: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 163/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5249 - acc: 0.7812\n",
      "Epoch 163: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 164/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5239 - acc: 0.7820\n",
      "Epoch 164: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 165/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5250 - acc: 0.7810\n",
      "Epoch 165: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 166/200\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5222 - acc: 0.7833\n",
      "Epoch 166: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 167/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5206 - acc: 0.7845\n",
      "Epoch 167: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 168/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5263 - acc: 0.7800\n",
      "Epoch 168: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 169/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5233 - acc: 0.7824\n",
      "Epoch 169: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 170/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5235 - acc: 0.7822\n",
      "Epoch 170: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 171/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5233 - acc: 0.7824\n",
      "Epoch 171: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 172/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5249 - acc: 0.7811\n",
      "Epoch 172: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 173/200\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.5235 - acc: 0.7822\n",
      "Epoch 173: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 174/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5279 - acc: 0.7787\n",
      "Epoch 174: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 175/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5277 - acc: 0.7789\n",
      "Epoch 175: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 176/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5259 - acc: 0.7804\n",
      "Epoch 176: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 177/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5220 - acc: 0.7834\n",
      "Epoch 177: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 178/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5269 - acc: 0.7796\n",
      "Epoch 178: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 179/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5207 - acc: 0.7844\n",
      "Epoch 179: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5578 - val_acc: 0.7709\n",
      "Epoch 180/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5245 - acc: 0.7814\n",
      "Epoch 180: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5578 - val_acc: 0.7709\n",
      "Epoch 181/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5226 - acc: 0.7829\n",
      "Epoch 181: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5578 - val_acc: 0.7709\n",
      "Epoch 182/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5230 - acc: 0.7826\n",
      "Epoch 182: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5578 - val_acc: 0.7709\n",
      "Epoch 183/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5247 - acc: 0.7812\n",
      "Epoch 183: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5578 - val_acc: 0.7709\n",
      "Epoch 184/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5260 - acc: 0.7803\n",
      "Epoch 184: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5578 - val_acc: 0.7709\n",
      "Epoch 185/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5221 - acc: 0.7833\n",
      "Epoch 185: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 186/200\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.5240 - acc: 0.7818\n",
      "Epoch 186: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 187/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5248 - acc: 0.7812\n",
      "Epoch 187: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 188/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5243 - acc: 0.7816\n",
      "Epoch 188: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 189/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5250 - acc: 0.7810\n",
      "Epoch 189: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 190/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5231 - acc: 0.7826\n",
      "Epoch 190: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 191/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5225 - acc: 0.7831\n",
      "Epoch 191: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 192/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5261 - acc: 0.7802\n",
      "Epoch 192: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 193/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5264 - acc: 0.7799\n",
      "Epoch 193: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 194/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5233 - acc: 0.7823\n",
      "Epoch 194: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 195/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5253 - acc: 0.7808\n",
      "Epoch 195: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 196/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5251 - acc: 0.7810\n",
      "Epoch 196: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 197/200\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5242 - acc: 0.7817\n",
      "Epoch 197: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 198/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5236 - acc: 0.7822\n",
      "Epoch 198: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 199/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5267 - acc: 0.7797\n",
      "Epoch 199: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n",
      "Epoch 200/200\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5251 - acc: 0.7810\n",
      "Epoch 200: val_loss did not improve from 0.55726\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.7814 - val_loss: 0.5577 - val_acc: 0.7709\n"
     ]
    }
   ],
   "source": [
    "modelpath = os.path.join(model_dir, 'credit_{epoch:d}-{val_loss:.4f}.keras')\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=modelpath,  \n",
    "                               monitor = 'val_loss', \n",
    "                               verbose=1,\n",
    "                               save_best_only = True\n",
    "                               )\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "          epochs=200, \n",
    "          batch_size=1024, \n",
    "          validation_split=0.2, \n",
    "          verbose=1,\n",
    "          callbacks = [checkpointer]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model(os.path.join(model_dir,'credit_115-0.5573.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 1s 2ms/step - loss: 1.9743 - acc: 0.7784\n"
     ]
    }
   ],
   "source": [
    "evaluation = loaded_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "loss = history.history['loss']\n",
    "val_acc = history.history['val_acc']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = range(1,len(acc)+1)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training Loss')\n",
    "plt.plot(epochs, val_loss, 'black', label = 'Validation loss')\n",
    "plt.title('T. and V. Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = range(1,len(acc)+1)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training Acc')\n",
    "plt.plot(epochs, val_acc, 'black', label = 'Validation Acc')\n",
    "plt.title('T. and V. Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\elice_python\\\\GAS_5\\\\pytest\\\\datasets\\\\bike_sharing'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = 'D:\\\\elice_python\\\\GAS_5\\\\pytest\\\\datasets\\\\bike_sharing'\n",
    "os.chdir(path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  \n",
       "0        81        0.0       3          13     16  \n",
       "1        80        0.0       8          32     40  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bike_train.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10886 entries, 0 to 10885\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   datetime    10886 non-null  object \n",
      " 1   season      10886 non-null  int64  \n",
      " 2   holiday     10886 non-null  int64  \n",
      " 3   workingday  10886 non-null  int64  \n",
      " 4   weather     10886 non-null  int64  \n",
      " 5   temp        10886 non-null  float64\n",
      " 6   atemp       10886 non-null  float64\n",
      " 7   humidity    10886 non-null  int64  \n",
      " 8   windspeed   10886 non-null  float64\n",
      " 9   casual      10886 non-null  int64  \n",
      " 10  registered  10886 non-null  int64  \n",
      " 11  count       10886 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(1)\n",
      "memory usage: 1020.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.datetime = pd.to_datetime(df.datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10886 entries, 0 to 10885\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   datetime    10886 non-null  datetime64[ns]\n",
      " 1   season      10886 non-null  int64         \n",
      " 2   holiday     10886 non-null  int64         \n",
      " 3   workingday  10886 non-null  int64         \n",
      " 4   weather     10886 non-null  int64         \n",
      " 5   temp        10886 non-null  float64       \n",
      " 6   atemp       10886 non-null  float64       \n",
      " 7   humidity    10886 non-null  int64         \n",
      " 8   windspeed   10886 non-null  float64       \n",
      " 9   casual      10886 non-null  int64         \n",
      " 10  registered  10886 non-null  int64         \n",
      " 11  count       10886 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(3), int64(8)\n",
      "memory usage: 1020.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-01-01 01:00:00')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.datetime[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10886 entries, 0 to 10885\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   datetime    10886 non-null  datetime64[ns]\n",
      " 1   season      10886 non-null  int64         \n",
      " 2   holiday     10886 non-null  int64         \n",
      " 3   workingday  10886 non-null  int64         \n",
      " 4   weather     10886 non-null  int64         \n",
      " 5   temp        10886 non-null  float64       \n",
      " 6   atemp       10886 non-null  float64       \n",
      " 7   humidity    10886 non-null  int64         \n",
      " 8   windspeed   10886 non-null  float64       \n",
      " 9   casual      10886 non-null  int64         \n",
      " 10  registered  10886 non-null  int64         \n",
      " 11  count       10886 non-null  int64         \n",
      " 12  year        10886 non-null  int32         \n",
      " 13  month       10886 non-null  int32         \n",
      " 14  hour        10886 non-null  int32         \n",
      "dtypes: datetime64[ns](1), float64(3), int32(3), int64(8)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "df['year'] = df['datetime'].dt.year\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### except-one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10886, 10), (10886,))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['count'].astype('float64')\n",
    "X = df[['workingday','temp','humidity','windspeed','weather','hour']]\n",
    "X = pd.get_dummies(X, columns=['workingday', 'weather'], drop_first=False, dtype='int32')\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10886 entries, 0 to 10885\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   temp          10886 non-null  float64\n",
      " 1   humidity      10886 non-null  int64  \n",
      " 2   windspeed     10886 non-null  float64\n",
      " 3   hour          10886 non-null  int32  \n",
      " 4   workingday_0  10886 non-null  int32  \n",
      " 5   workingday_1  10886 non-null  int32  \n",
      " 6   weather_1     10886 non-null  int32  \n",
      " 7   weather_2     10886 non-null  int32  \n",
      " 8   weather_3     10886 non-null  int32  \n",
      " 9   weather_4     10886 non-null  int32  \n",
      "dtypes: float64(2), int32(7), int64(1)\n",
      "memory usage: 552.9 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16.0\n",
       "1    40.0\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input((10,)))\n",
    "model.add(Dense(24, activation = 'relu', input_shape = (10,)))\n",
    "model.add(Dense(48, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(18, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_81 (Dense)            (None, 24)                264       \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 48)                1200      \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 32)                1568      \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 18)                594       \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 8)                 152       \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,787\n",
      "Trainable params: 3,787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# 모델 컴파일 시 사용자 정의 손실 함수 사용\n",
    "model.compile(optimizer='adam', loss=rmse, metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/7 [===>..........................] - ETA: 3s - loss: 273.2574 - mae: 200.7406\n",
      "Epoch 1: val_loss improved from inf to 252.42403, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 1s 52ms/step - loss: 264.6993 - mae: 191.8085 - val_loss: 252.4240 - val_mae: 181.3561\n",
      "Epoch 2/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 277.4428 - mae: 202.7895\n",
      "Epoch 2: val_loss improved from 252.42403 to 250.96552, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 263.2358 - mae: 189.9137 - val_loss: 250.9655 - val_mae: 179.4754\n",
      "Epoch 3/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 256.1992 - mae: 183.5211\n",
      "Epoch 3: val_loss improved from 250.96552 to 248.78857, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 261.5919 - mae: 187.8107 - val_loss: 248.7886 - val_mae: 176.9558\n",
      "Epoch 4/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 254.7806 - mae: 181.9310\n",
      "Epoch 4: val_loss improved from 248.78857 to 245.18175, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 259.0833 - mae: 184.7872 - val_loss: 245.1817 - val_mae: 173.1718\n",
      "Epoch 5/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 245.4018 - mae: 170.5354\n",
      "Epoch 5: val_loss improved from 245.18175 to 239.24229, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 254.6730 - mae: 180.3674 - val_loss: 239.2423 - val_mae: 167.5276\n",
      "Epoch 6/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 256.4781 - mae: 181.0366\n",
      "Epoch 6: val_loss improved from 239.24229 to 229.75475, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 247.6256 - mae: 174.0842 - val_loss: 229.7547 - val_mae: 159.9710\n",
      "Epoch 7/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 235.4365 - mae: 164.7731\n",
      "Epoch 7: val_loss improved from 229.75475 to 215.37747, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 236.3647 - mae: 165.5213 - val_loss: 215.3775 - val_mae: 150.5234\n",
      "Epoch 8/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 234.1673 - mae: 163.0635\n",
      "Epoch 8: val_loss improved from 215.37747 to 197.15428, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 219.9609 - mae: 155.5815 - val_loss: 197.1543 - val_mae: 141.7875\n",
      "Epoch 9/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 205.4301 - mae: 148.6869\n",
      "Epoch 9: val_loss improved from 197.15428 to 186.57834, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 202.2072 - mae: 149.7427 - val_loss: 186.5783 - val_mae: 143.8637\n",
      "Epoch 10/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 192.7368 - mae: 147.4245\n",
      "Epoch 10: val_loss did not improve from 186.57834\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 195.9890 - mae: 155.0139 - val_loss: 189.3471 - val_mae: 152.4161\n",
      "Epoch 11/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 201.8287 - mae: 161.7993\n",
      "Epoch 11: val_loss improved from 186.57834 to 183.57433, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 195.1116 - mae: 156.2042 - val_loss: 183.5743 - val_mae: 144.6732\n",
      "Epoch 12/400\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 190.6883 - mae: 149.1873\n",
      "Epoch 12: val_loss improved from 183.57433 to 180.00558, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 190.6228 - mae: 148.4995 - val_loss: 180.0056 - val_mae: 137.8141\n",
      "Epoch 13/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 192.0990 - mae: 147.9253\n",
      "Epoch 13: val_loss improved from 180.00558 to 177.41589, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 188.2683 - mae: 144.1484 - val_loss: 177.4159 - val_mae: 135.6282\n",
      "Epoch 14/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 193.3586 - mae: 147.2214\n",
      "Epoch 14: val_loss improved from 177.41589 to 174.64375, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 185.0488 - mae: 142.6318 - val_loss: 174.6438 - val_mae: 135.6335\n",
      "Epoch 15/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 198.2429 - mae: 153.3081\n",
      "Epoch 15: val_loss improved from 174.64375 to 171.83154, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 181.6043 - mae: 142.1503 - val_loss: 171.8315 - val_mae: 134.6759\n",
      "Epoch 16/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 180.9899 - mae: 140.4771\n",
      "Epoch 16: val_loss improved from 171.83154 to 168.03575, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 178.2369 - mae: 139.5392 - val_loss: 168.0358 - val_mae: 130.5238\n",
      "Epoch 17/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 179.4602 - mae: 138.1483\n",
      "Epoch 17: val_loss improved from 168.03575 to 163.99992, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 174.3214 - mae: 135.1771 - val_loss: 163.9999 - val_mae: 126.6801\n",
      "Epoch 18/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 173.2249 - mae: 133.4075\n",
      "Epoch 18: val_loss improved from 163.99992 to 159.79604, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 169.7608 - mae: 132.0381 - val_loss: 159.7960 - val_mae: 124.3884\n",
      "Epoch 19/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 165.8371 - mae: 126.3964\n",
      "Epoch 19: val_loss improved from 159.79604 to 154.97824, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 164.7572 - mae: 128.4755 - val_loss: 154.9782 - val_mae: 119.3075\n",
      "Epoch 20/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 163.1065 - mae: 126.5893\n",
      "Epoch 20: val_loss improved from 154.97824 to 150.76784, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 159.6662 - mae: 122.3180 - val_loss: 150.7678 - val_mae: 114.3536\n",
      "Epoch 21/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 159.6916 - mae: 120.4558\n",
      "Epoch 21: val_loss improved from 150.76784 to 147.87283, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 155.0323 - mae: 118.8540 - val_loss: 147.8728 - val_mae: 111.0980\n",
      "Epoch 22/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 150.9354 - mae: 115.1728\n",
      "Epoch 22: val_loss improved from 147.87283 to 146.58733, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 151.6756 - mae: 113.1968 - val_loss: 146.5873 - val_mae: 106.9972\n",
      "Epoch 23/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 150.1037 - mae: 110.3263\n",
      "Epoch 23: val_loss did not improve from 146.58733\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 149.9063 - mae: 111.5115 - val_loss: 146.7326 - val_mae: 107.1774\n",
      "Epoch 24/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 143.9656 - mae: 105.5222\n",
      "Epoch 24: val_loss did not improve from 146.58733\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 149.2390 - mae: 109.2039 - val_loss: 146.7066 - val_mae: 104.6543\n",
      "Epoch 25/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 139.0094 - mae: 103.0744\n",
      "Epoch 25: val_loss did not improve from 146.58733\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 148.7256 - mae: 107.8899 - val_loss: 146.6939 - val_mae: 107.4855\n",
      "Epoch 26/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 147.5447 - mae: 111.7003\n",
      "Epoch 26: val_loss improved from 146.58733 to 146.17905, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 148.7334 - mae: 110.0255 - val_loss: 146.1790 - val_mae: 105.7895\n",
      "Epoch 27/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 146.2639 - mae: 107.6924\n",
      "Epoch 27: val_loss improved from 146.17905 to 146.03630, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 148.3019 - mae: 109.4289 - val_loss: 146.0363 - val_mae: 106.3091\n",
      "Epoch 28/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 150.6991 - mae: 113.5054\n",
      "Epoch 28: val_loss improved from 146.03630 to 145.63991, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 148.0657 - mae: 108.3012 - val_loss: 145.6399 - val_mae: 105.1786\n",
      "Epoch 29/400\n",
      "4/7 [================>.............] - ETA: 0s - loss: 149.2131 - mae: 109.8089\n",
      "Epoch 29: val_loss improved from 145.63991 to 145.37035, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 147.7381 - mae: 108.9448 - val_loss: 145.3703 - val_mae: 104.4708\n",
      "Epoch 30/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 148.4883 - mae: 106.3551\n",
      "Epoch 30: val_loss improved from 145.37035 to 145.09911, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 147.4998 - mae: 107.4600 - val_loss: 145.0991 - val_mae: 104.9381\n",
      "Epoch 31/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 147.3860 - mae: 107.2777\n",
      "Epoch 31: val_loss improved from 145.09911 to 144.76289, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 147.2384 - mae: 107.1101 - val_loss: 144.7629 - val_mae: 104.8298\n",
      "Epoch 32/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 140.9827 - mae: 101.8115\n",
      "Epoch 32: val_loss improved from 144.76289 to 144.43285, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 146.8623 - mae: 108.2089 - val_loss: 144.4328 - val_mae: 103.4170\n",
      "Epoch 33/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 137.7084 - mae: 101.0731\n",
      "Epoch 33: val_loss improved from 144.43285 to 144.29820, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 146.7159 - mae: 106.0145 - val_loss: 144.2982 - val_mae: 105.5904\n",
      "Epoch 34/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 147.9491 - mae: 108.7084\n",
      "Epoch 34: val_loss improved from 144.29820 to 143.89784, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 146.3349 - mae: 107.4015 - val_loss: 143.8978 - val_mae: 101.8896\n",
      "Epoch 35/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 149.1043 - mae: 107.3725\n",
      "Epoch 35: val_loss improved from 143.89784 to 143.61226, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 145.9367 - mae: 106.4244 - val_loss: 143.6123 - val_mae: 103.4524\n",
      "Epoch 36/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 144.0321 - mae: 105.3677\n",
      "Epoch 36: val_loss improved from 143.61226 to 143.15935, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 145.5192 - mae: 104.7262 - val_loss: 143.1593 - val_mae: 102.4393\n",
      "Epoch 37/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 144.4662 - mae: 103.9502\n",
      "Epoch 37: val_loss improved from 143.15935 to 142.76367, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 145.1745 - mae: 106.4398 - val_loss: 142.7637 - val_mae: 101.7249\n",
      "Epoch 38/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 153.4497 - mae: 110.2345\n",
      "Epoch 38: val_loss improved from 142.76367 to 142.50581, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 144.7458 - mae: 103.7824 - val_loss: 142.5058 - val_mae: 102.6302\n",
      "Epoch 39/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 146.8063 - mae: 105.9566\n",
      "Epoch 39: val_loss improved from 142.50581 to 142.08557, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 144.3028 - mae: 105.3232 - val_loss: 142.0856 - val_mae: 99.9708\n",
      "Epoch 40/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 142.1812 - mae: 102.3593\n",
      "Epoch 40: val_loss improved from 142.08557 to 141.66940, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 143.8729 - mae: 103.3583 - val_loss: 141.6694 - val_mae: 101.3790\n",
      "Epoch 41/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 146.6417 - mae: 106.0895\n",
      "Epoch 41: val_loss improved from 141.66940 to 141.34804, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 143.4392 - mae: 103.4080 - val_loss: 141.3480 - val_mae: 101.1409\n",
      "Epoch 42/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 143.8480 - mae: 103.1683\n",
      "Epoch 42: val_loss improved from 141.34804 to 141.14233, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 143.0200 - mae: 104.5950 - val_loss: 141.1423 - val_mae: 97.9817\n",
      "Epoch 43/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 139.1692 - mae: 99.0244\n",
      "Epoch 43: val_loss improved from 141.14233 to 141.03772, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 142.8749 - mae: 101.3077 - val_loss: 141.0377 - val_mae: 103.3112\n",
      "Epoch 44/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 137.9386 - mae: 103.6111\n",
      "Epoch 44: val_loss improved from 141.03772 to 140.06241, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 142.4104 - mae: 102.9337 - val_loss: 140.0624 - val_mae: 98.7403\n",
      "Epoch 45/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 149.8678 - mae: 108.0192\n",
      "Epoch 45: val_loss improved from 140.06241 to 139.68091, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 141.7437 - mae: 102.9816 - val_loss: 139.6809 - val_mae: 97.8546\n",
      "Epoch 46/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 142.3385 - mae: 102.0238\n",
      "Epoch 46: val_loss improved from 139.68091 to 138.89351, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 141.0923 - mae: 101.1528 - val_loss: 138.8935 - val_mae: 98.7020\n",
      "Epoch 47/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 130.2405 - mae: 93.0146\n",
      "Epoch 47: val_loss improved from 138.89351 to 138.67160, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 140.4868 - mae: 100.9490 - val_loss: 138.6716 - val_mae: 98.5382\n",
      "Epoch 48/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 141.2775 - mae: 101.2965\n",
      "Epoch 48: val_loss improved from 138.67160 to 137.94504, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 139.9283 - mae: 100.3641 - val_loss: 137.9450 - val_mae: 97.8795\n",
      "Epoch 49/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 137.4162 - mae: 100.4320\n",
      "Epoch 49: val_loss improved from 137.94504 to 137.73224, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 139.4813 - mae: 100.0402 - val_loss: 137.7322 - val_mae: 98.3132\n",
      "Epoch 50/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 145.0375 - mae: 105.1997\n",
      "Epoch 50: val_loss improved from 137.73224 to 137.07021, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 139.1584 - mae: 99.9890 - val_loss: 137.0702 - val_mae: 95.7687\n",
      "Epoch 51/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 139.2645 - mae: 98.2098\n",
      "Epoch 51: val_loss improved from 137.07021 to 136.79732, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 138.5079 - mae: 99.5969 - val_loss: 136.7973 - val_mae: 97.0837\n",
      "Epoch 52/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 138.3376 - mae: 98.7846\n",
      "Epoch 52: val_loss improved from 136.79732 to 136.20161, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 138.0468 - mae: 98.4717 - val_loss: 136.2016 - val_mae: 96.7376\n",
      "Epoch 53/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 137.7421 - mae: 100.1335\n",
      "Epoch 53: val_loss improved from 136.20161 to 135.73711, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 137.4929 - mae: 98.6164 - val_loss: 135.7371 - val_mae: 95.8820\n",
      "Epoch 54/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 135.6067 - mae: 96.4821\n",
      "Epoch 54: val_loss improved from 135.73711 to 135.18224, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 137.0612 - mae: 98.0613 - val_loss: 135.1822 - val_mae: 94.5052\n",
      "Epoch 55/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 136.7581 - mae: 97.0609\n",
      "Epoch 55: val_loss improved from 135.18224 to 134.95238, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 136.6420 - mae: 97.3221 - val_loss: 134.9524 - val_mae: 96.3613\n",
      "Epoch 56/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 134.9519 - mae: 96.1320\n",
      "Epoch 56: val_loss did not improve from 134.95238\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 136.1630 - mae: 97.9806 - val_loss: 134.9560 - val_mae: 91.9259\n",
      "Epoch 57/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 128.3177 - mae: 87.4893\n",
      "Epoch 57: val_loss improved from 134.95238 to 133.96628, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 136.3589 - mae: 97.3314 - val_loss: 133.9663 - val_mae: 93.6250\n",
      "Epoch 58/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 134.4126 - mae: 96.1324\n",
      "Epoch 58: val_loss did not improve from 133.96628\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 135.7119 - mae: 95.8050 - val_loss: 134.1016 - val_mae: 95.9805\n",
      "Epoch 59/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 132.1400 - mae: 95.3600\n",
      "Epoch 59: val_loss improved from 133.96628 to 133.54294, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 135.2870 - mae: 96.0144 - val_loss: 133.5429 - val_mae: 95.5742\n",
      "Epoch 60/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 136.8041 - mae: 99.4677\n",
      "Epoch 60: val_loss improved from 133.54294 to 133.21008, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 134.8427 - mae: 96.0572 - val_loss: 133.2101 - val_mae: 92.0162\n",
      "Epoch 61/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 139.7786 - mae: 96.8331\n",
      "Epoch 61: val_loss improved from 133.21008 to 132.74706, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 134.7388 - mae: 96.4950 - val_loss: 132.7471 - val_mae: 91.1785\n",
      "Epoch 62/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 135.5952 - mae: 92.4712\n",
      "Epoch 62: val_loss did not improve from 132.74706\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 134.3717 - mae: 94.5111 - val_loss: 133.7067 - val_mae: 97.2747\n",
      "Epoch 63/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 133.2319 - mae: 98.3576\n",
      "Epoch 63: val_loss improved from 132.74706 to 132.58954, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 134.3476 - mae: 94.8577 - val_loss: 132.5895 - val_mae: 95.2778\n",
      "Epoch 64/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 134.8908 - mae: 96.9456\n",
      "Epoch 64: val_loss improved from 132.58954 to 132.49730, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 133.9543 - mae: 95.4494 - val_loss: 132.4973 - val_mae: 89.9400\n",
      "Epoch 65/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 133.8138 - mae: 92.1478\n",
      "Epoch 65: val_loss improved from 132.49730 to 131.65115, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 133.7536 - mae: 94.9507 - val_loss: 131.6512 - val_mae: 91.1249\n",
      "Epoch 66/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 136.3716 - mae: 93.9848\n",
      "Epoch 66: val_loss did not improve from 131.65115\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 133.3631 - mae: 93.6521 - val_loss: 131.7055 - val_mae: 93.5019\n",
      "Epoch 67/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 133.1899 - mae: 94.5835\n",
      "Epoch 67: val_loss improved from 131.65115 to 131.30348, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 133.0853 - mae: 94.6160 - val_loss: 131.3035 - val_mae: 90.1378\n",
      "Epoch 68/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 132.4744 - mae: 90.4798\n",
      "Epoch 68: val_loss improved from 131.30348 to 131.22147, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 133.0281 - mae: 94.2844 - val_loss: 131.2215 - val_mae: 91.3979\n",
      "Epoch 69/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 135.3937 - mae: 94.2976\n",
      "Epoch 69: val_loss improved from 131.22147 to 130.85455, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 132.6214 - mae: 93.1334 - val_loss: 130.8546 - val_mae: 91.7019\n",
      "Epoch 70/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 127.8404 - mae: 90.0357\n",
      "Epoch 70: val_loss did not improve from 130.85455\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 132.7322 - mae: 92.8770 - val_loss: 132.1190 - val_mae: 95.6624\n",
      "Epoch 71/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 132.0228 - mae: 94.7098\n",
      "Epoch 71: val_loss improved from 130.85455 to 130.72153, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 132.4868 - mae: 93.1697 - val_loss: 130.7215 - val_mae: 92.5093\n",
      "Epoch 72/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 128.9034 - mae: 91.3613\n",
      "Epoch 72: val_loss did not improve from 130.72153\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 132.1129 - mae: 93.9881 - val_loss: 130.7770 - val_mae: 88.2750\n",
      "Epoch 73/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 127.5321 - mae: 88.0835\n",
      "Epoch 73: val_loss did not improve from 130.72153\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 132.4286 - mae: 92.5958 - val_loss: 131.2347 - val_mae: 94.2887\n",
      "Epoch 74/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 131.6483 - mae: 94.5752\n",
      "Epoch 74: val_loss did not improve from 130.72153\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 132.0406 - mae: 91.8308 - val_loss: 130.7361 - val_mae: 92.8828\n",
      "Epoch 75/400\n",
      "4/7 [================>.............] - ETA: 0s - loss: 131.4643 - mae: 92.6924\n",
      "Epoch 75: val_loss improved from 130.72153 to 129.89128, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 131.8600 - mae: 92.5203 - val_loss: 129.8913 - val_mae: 90.9913\n",
      "Epoch 76/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 123.0707 - mae: 87.1478\n",
      "Epoch 76: val_loss did not improve from 129.89128\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 131.3789 - mae: 92.1828 - val_loss: 130.0090 - val_mae: 91.0370\n",
      "Epoch 77/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 131.9564 - mae: 92.9932\n",
      "Epoch 77: val_loss improved from 129.89128 to 129.74815, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 131.2763 - mae: 91.8100 - val_loss: 129.7482 - val_mae: 91.5799\n",
      "Epoch 78/400\n",
      "2/7 [=======>......................] - ETA: 0s - loss: 131.5783 - mae: 92.6986\n",
      "Epoch 78: val_loss improved from 129.74815 to 129.27321, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 131.3322 - mae: 91.7412 - val_loss: 129.2732 - val_mae: 90.0735\n",
      "Epoch 79/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 132.0181 - mae: 92.4985\n",
      "Epoch 79: val_loss improved from 129.27321 to 129.21686, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 131.1670 - mae: 92.2781 - val_loss: 129.2169 - val_mae: 87.5860\n",
      "Epoch 80/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 131.7181 - mae: 89.0868\n",
      "Epoch 80: val_loss improved from 129.21686 to 129.01590, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 130.9014 - mae: 91.1039 - val_loss: 129.0159 - val_mae: 90.3011\n",
      "Epoch 81/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 126.8278 - mae: 90.6448\n",
      "Epoch 81: val_loss did not improve from 129.01590\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 130.9347 - mae: 90.1585 - val_loss: 131.8211 - val_mae: 96.2328\n",
      "Epoch 82/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 133.5535 - mae: 97.4501\n",
      "Epoch 82: val_loss improved from 129.01590 to 128.82347, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 131.6135 - mae: 91.8835 - val_loss: 128.8235 - val_mae: 89.7577\n",
      "Epoch 83/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 132.1182 - mae: 92.2387\n",
      "Epoch 83: val_loss improved from 128.82347 to 128.78130, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 130.8983 - mae: 92.2369 - val_loss: 128.7813 - val_mae: 86.2846\n",
      "Epoch 84/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 133.0004 - mae: 88.5971\n",
      "Epoch 84: val_loss improved from 128.78130 to 128.41183, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 130.5698 - mae: 91.6317 - val_loss: 128.4118 - val_mae: 86.6859\n",
      "Epoch 85/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 127.1477 - mae: 87.4785\n",
      "Epoch 85: val_loss did not improve from 128.41183\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 130.1243 - mae: 89.8872 - val_loss: 128.9632 - val_mae: 91.0222\n",
      "Epoch 86/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 124.8271 - mae: 90.2899\n",
      "Epoch 86: val_loss did not improve from 128.41183\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 130.1987 - mae: 89.7197 - val_loss: 129.2913 - val_mae: 91.8778\n",
      "Epoch 87/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 130.9806 - mae: 91.9302\n",
      "Epoch 87: val_loss improved from 128.41183 to 127.83369, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 130.1286 - mae: 91.3229 - val_loss: 127.8337 - val_mae: 86.4253\n",
      "Epoch 88/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 138.8100 - mae: 91.4072\n",
      "Epoch 88: val_loss improved from 127.83369 to 127.68862, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 129.6634 - mae: 90.1704 - val_loss: 127.6886 - val_mae: 87.5867\n",
      "Epoch 89/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 131.6307 - mae: 92.3658\n",
      "Epoch 89: val_loss improved from 127.68862 to 127.44594, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 129.4300 - mae: 89.7297 - val_loss: 127.4459 - val_mae: 86.4322\n",
      "Epoch 90/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 131.5978 - mae: 89.7872\n",
      "Epoch 90: val_loss did not improve from 127.44594\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 129.3070 - mae: 89.5368 - val_loss: 127.6609 - val_mae: 88.9859\n",
      "Epoch 91/400\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 129.4224 - mae: 88.9167\n",
      "Epoch 91: val_loss did not improve from 127.44594\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 129.3259 - mae: 88.8500 - val_loss: 128.6126 - val_mae: 91.0988\n",
      "Epoch 92/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 127.8868 - mae: 88.8865\n",
      "Epoch 92: val_loss improved from 127.44594 to 127.28717, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 129.1290 - mae: 90.6010 - val_loss: 127.2872 - val_mae: 84.6410\n",
      "Epoch 93/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 131.9350 - mae: 87.7256\n",
      "Epoch 93: val_loss improved from 127.28717 to 127.20448, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 129.3416 - mae: 89.6403 - val_loss: 127.2045 - val_mae: 85.1635\n",
      "Epoch 94/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 130.0543 - mae: 89.4854\n",
      "Epoch 94: val_loss did not improve from 127.20448\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 128.8109 - mae: 88.4676 - val_loss: 127.7268 - val_mae: 89.7785\n",
      "Epoch 95/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 121.0736 - mae: 86.8996\n",
      "Epoch 95: val_loss improved from 127.20448 to 126.89827, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 128.5921 - mae: 88.5622 - val_loss: 126.8983 - val_mae: 87.5584\n",
      "Epoch 96/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 128.5242 - mae: 88.9254\n",
      "Epoch 96: val_loss improved from 126.89827 to 126.72459, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 128.5753 - mae: 88.7393 - val_loss: 126.7246 - val_mae: 86.8626\n",
      "Epoch 97/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 133.6148 - mae: 92.9607\n",
      "Epoch 97: val_loss did not improve from 126.72459\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 128.2187 - mae: 89.1928 - val_loss: 127.0009 - val_mae: 83.5134\n",
      "Epoch 98/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 136.9430 - mae: 91.5169\n",
      "Epoch 98: val_loss improved from 126.72459 to 126.22735, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 128.9331 - mae: 89.0722 - val_loss: 126.2273 - val_mae: 84.6330\n",
      "Epoch 99/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 130.3946 - mae: 88.8350\n",
      "Epoch 99: val_loss did not improve from 126.22735\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 128.0479 - mae: 87.6194 - val_loss: 126.6120 - val_mae: 88.0588\n",
      "Epoch 100/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 131.5348 - mae: 92.2547\n",
      "Epoch 100: val_loss did not improve from 126.22735\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 127.9565 - mae: 87.5424 - val_loss: 126.6600 - val_mae: 88.4112\n",
      "Epoch 101/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 125.8842 - mae: 87.3673\n",
      "Epoch 101: val_loss improved from 126.22735 to 125.81610, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 127.7898 - mae: 88.1396 - val_loss: 125.8161 - val_mae: 85.8239\n",
      "Epoch 102/400\n",
      "2/7 [=======>......................] - ETA: 0s - loss: 131.1915 - mae: 90.1942\n",
      "Epoch 102: val_loss improved from 125.81610 to 125.70235, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 127.5130 - mae: 87.8109 - val_loss: 125.7023 - val_mae: 84.6578\n",
      "Epoch 103/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 131.8107 - mae: 89.2858\n",
      "Epoch 103: val_loss improved from 125.70235 to 125.66585, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 127.4612 - mae: 88.0079 - val_loss: 125.6658 - val_mae: 83.9416\n",
      "Epoch 104/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 121.9839 - mae: 81.3913\n",
      "Epoch 104: val_loss improved from 125.66585 to 125.24223, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 127.2661 - mae: 87.8130 - val_loss: 125.2422 - val_mae: 84.7397\n",
      "Epoch 105/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 121.2611 - mae: 83.2581\n",
      "Epoch 105: val_loss did not improve from 125.24223\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 127.0956 - mae: 86.5807 - val_loss: 126.0079 - val_mae: 86.9446\n",
      "Epoch 106/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 125.5538 - mae: 88.9646\n",
      "Epoch 106: val_loss did not improve from 125.24223\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 127.0797 - mae: 86.6824 - val_loss: 125.3988 - val_mae: 86.0884\n",
      "Epoch 107/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 121.4244 - mae: 83.9678\n",
      "Epoch 107: val_loss improved from 125.24223 to 124.96747, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 126.6143 - mae: 87.5055 - val_loss: 124.9675 - val_mae: 83.6047\n",
      "Epoch 108/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 128.0621 - mae: 85.7565\n",
      "Epoch 108: val_loss did not improve from 124.96747\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 126.4550 - mae: 86.8471 - val_loss: 125.1838 - val_mae: 83.5452\n",
      "Epoch 109/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 128.2797 - mae: 83.6677\n",
      "Epoch 109: val_loss did not improve from 124.96747\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 126.6271 - mae: 86.1930 - val_loss: 125.0953 - val_mae: 86.1048\n",
      "Epoch 110/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 130.4175 - mae: 91.3056\n",
      "Epoch 110: val_loss improved from 124.96747 to 124.58271, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 126.1970 - mae: 86.2390 - val_loss: 124.5827 - val_mae: 84.2521\n",
      "Epoch 111/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 128.9748 - mae: 88.0948\n",
      "Epoch 111: val_loss did not improve from 124.58271\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 125.8735 - mae: 85.8272 - val_loss: 124.8183 - val_mae: 85.8306\n",
      "Epoch 112/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 128.2837 - mae: 87.7049\n",
      "Epoch 112: val_loss improved from 124.58271 to 124.30309, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 125.8280 - mae: 86.2536 - val_loss: 124.3031 - val_mae: 83.7169\n",
      "Epoch 113/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 129.9366 - mae: 87.5357\n",
      "Epoch 113: val_loss did not improve from 124.30309\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 126.0273 - mae: 86.5210 - val_loss: 124.7809 - val_mae: 81.1355\n",
      "Epoch 114/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 119.0519 - mae: 78.3062\n",
      "Epoch 114: val_loss improved from 124.30309 to 124.28011, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 125.8210 - mae: 86.1683 - val_loss: 124.2801 - val_mae: 83.9475\n",
      "Epoch 115/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 126.6059 - mae: 86.3583\n",
      "Epoch 115: val_loss improved from 124.28011 to 124.19630, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 125.5505 - mae: 85.1307 - val_loss: 124.1963 - val_mae: 84.4590\n",
      "Epoch 116/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 120.3938 - mae: 82.6380\n",
      "Epoch 116: val_loss did not improve from 124.19630\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 125.3256 - mae: 85.0116 - val_loss: 125.2374 - val_mae: 87.1969\n",
      "Epoch 117/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 128.5725 - mae: 89.3433\n",
      "Epoch 117: val_loss improved from 124.19630 to 123.67868, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 125.1130 - mae: 85.3149 - val_loss: 123.6787 - val_mae: 83.5263\n",
      "Epoch 118/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 127.5125 - mae: 85.3753\n",
      "Epoch 118: val_loss did not improve from 123.67868\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 124.9230 - mae: 84.8575 - val_loss: 124.1956 - val_mae: 84.5949\n",
      "Epoch 119/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 127.1732 - mae: 88.0006\n",
      "Epoch 119: val_loss improved from 123.67868 to 123.37755, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 124.8591 - mae: 85.1707 - val_loss: 123.3775 - val_mae: 81.6802\n",
      "Epoch 120/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 131.1103 - mae: 88.4787\n",
      "Epoch 120: val_loss did not improve from 123.37755\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 124.3504 - mae: 84.8507 - val_loss: 123.3935 - val_mae: 82.7737\n",
      "Epoch 121/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 125.5682 - mae: 84.1581\n",
      "Epoch 121: val_loss improved from 123.37755 to 123.09093, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 124.4665 - mae: 84.4544 - val_loss: 123.0909 - val_mae: 82.8105\n",
      "Epoch 122/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 126.0377 - mae: 86.0757\n",
      "Epoch 122: val_loss did not improve from 123.09093\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 124.2541 - mae: 83.5378 - val_loss: 125.4546 - val_mae: 87.8217\n",
      "Epoch 123/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 123.3839 - mae: 86.7422\n",
      "Epoch 123: val_loss did not improve from 123.09093\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 124.4587 - mae: 84.3625 - val_loss: 123.2539 - val_mae: 83.7253\n",
      "Epoch 124/400\n",
      "7/7 [==============================] - ETA: 0s - loss: 123.8996 - mae: 84.5278\n",
      "Epoch 124: val_loss improved from 123.09093 to 122.91898, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 123.8996 - mae: 84.5278 - val_loss: 122.9190 - val_mae: 82.9502\n",
      "Epoch 125/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 125.3603 - mae: 84.1664\n",
      "Epoch 125: val_loss improved from 122.91898 to 122.53690, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 123.5394 - mae: 84.2332 - val_loss: 122.5369 - val_mae: 80.5798\n",
      "Epoch 126/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 122.6409 - mae: 80.7824\n",
      "Epoch 126: val_loss did not improve from 122.53690\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 123.8579 - mae: 83.6338 - val_loss: 123.0491 - val_mae: 83.4281\n",
      "Epoch 127/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 122.1750 - mae: 83.2115\n",
      "Epoch 127: val_loss did not improve from 122.53690\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 123.5360 - mae: 83.0680 - val_loss: 123.1067 - val_mae: 84.0150\n",
      "Epoch 128/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 126.3336 - mae: 87.4035\n",
      "Epoch 128: val_loss did not improve from 122.53690\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 123.3513 - mae: 83.4674 - val_loss: 122.7448 - val_mae: 83.6590\n",
      "Epoch 129/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 126.4182 - mae: 87.5113\n",
      "Epoch 129: val_loss did not improve from 122.53690\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 123.3425 - mae: 83.6685 - val_loss: 122.8508 - val_mae: 83.1352\n",
      "Epoch 130/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 124.0473 - mae: 83.2672\n",
      "Epoch 130: val_loss improved from 122.53690 to 122.28436, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 123.2249 - mae: 83.3294 - val_loss: 122.2844 - val_mae: 82.5839\n",
      "Epoch 131/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 117.8242 - mae: 82.0075\n",
      "Epoch 131: val_loss improved from 122.28436 to 121.99570, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 122.8669 - mae: 83.4572 - val_loss: 121.9957 - val_mae: 79.6565\n",
      "Epoch 132/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 124.4430 - mae: 82.4588\n",
      "Epoch 132: val_loss did not improve from 121.99570\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 123.5391 - mae: 83.7865 - val_loss: 122.3879 - val_mae: 81.5546\n",
      "Epoch 133/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 127.7033 - mae: 84.4215\n",
      "Epoch 133: val_loss improved from 121.99570 to 121.51560, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 122.8145 - mae: 83.4173 - val_loss: 121.5156 - val_mae: 80.4864\n",
      "Epoch 134/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 127.9701 - mae: 84.6699\n",
      "Epoch 134: val_loss improved from 121.51560 to 121.51246, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 122.5525 - mae: 82.5452 - val_loss: 121.5125 - val_mae: 79.9456\n",
      "Epoch 135/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 117.7417 - mae: 77.8211\n",
      "Epoch 135: val_loss did not improve from 121.51246\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 122.3896 - mae: 82.5189 - val_loss: 121.5512 - val_mae: 80.0958\n",
      "Epoch 136/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 125.4506 - mae: 83.4527\n",
      "Epoch 136: val_loss improved from 121.51246 to 121.33241, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 122.1267 - mae: 82.5863 - val_loss: 121.3324 - val_mae: 79.3873\n",
      "Epoch 137/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 122.3319 - mae: 81.8520\n",
      "Epoch 137: val_loss improved from 121.33241 to 121.16908, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 122.6211 - mae: 82.5370 - val_loss: 121.1691 - val_mae: 80.3515\n",
      "Epoch 138/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 128.1538 - mae: 85.6494\n",
      "Epoch 138: val_loss did not improve from 121.16908\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 122.0903 - mae: 81.5326 - val_loss: 123.2781 - val_mae: 85.1516\n",
      "Epoch 139/400\n",
      "4/7 [================>.............] - ETA: 0s - loss: 120.4070 - mae: 81.9183\n",
      "Epoch 139: val_loss did not improve from 121.16908\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 122.3089 - mae: 82.0846 - val_loss: 123.2945 - val_mae: 85.4456\n",
      "Epoch 140/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 126.2377 - mae: 86.6969\n",
      "Epoch 140: val_loss improved from 121.16908 to 121.05718, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 122.7204 - mae: 83.1548 - val_loss: 121.0572 - val_mae: 80.5308\n",
      "Epoch 141/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 126.3306 - mae: 83.9053\n",
      "Epoch 141: val_loss improved from 121.05718 to 120.93178, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 121.6190 - mae: 82.5474 - val_loss: 120.9318 - val_mae: 79.1826\n",
      "Epoch 142/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 119.6016 - mae: 79.7012\n",
      "Epoch 142: val_loss improved from 120.93178 to 120.69398, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 121.5602 - mae: 81.9976 - val_loss: 120.6940 - val_mae: 79.2495\n",
      "Epoch 143/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 120.4383 - mae: 80.9188\n",
      "Epoch 143: val_loss did not improve from 120.69398\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 121.2474 - mae: 80.9959 - val_loss: 122.0443 - val_mae: 83.2593\n",
      "Epoch 144/400\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 121.3477 - mae: 82.4252\n",
      "Epoch 144: val_loss improved from 120.69398 to 120.45191, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 121.6351 - mae: 82.2932 - val_loss: 120.4519 - val_mae: 78.9844\n",
      "Epoch 145/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 117.6075 - mae: 76.3069\n",
      "Epoch 145: val_loss did not improve from 120.45191\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 121.1320 - mae: 82.4582 - val_loss: 120.7470 - val_mae: 78.1360\n",
      "Epoch 146/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 124.9068 - mae: 81.3892\n",
      "Epoch 146: val_loss did not improve from 120.45191\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 121.2295 - mae: 81.3619 - val_loss: 120.4724 - val_mae: 79.4376\n",
      "Epoch 147/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 120.4667 - mae: 81.7296\n",
      "Epoch 147: val_loss improved from 120.45191 to 120.29790, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 120.8991 - mae: 81.1319 - val_loss: 120.2979 - val_mae: 78.3828\n",
      "Epoch 148/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 119.3844 - mae: 78.5560\n",
      "Epoch 148: val_loss improved from 120.29790 to 120.20995, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 121.0303 - mae: 81.2967 - val_loss: 120.2099 - val_mae: 79.9139\n",
      "Epoch 149/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 116.3259 - mae: 78.8096\n",
      "Epoch 149: val_loss did not improve from 120.20995\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 120.7011 - mae: 80.5709 - val_loss: 120.7374 - val_mae: 81.1897\n",
      "Epoch 150/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 120.7871 - mae: 80.4787\n",
      "Epoch 150: val_loss improved from 120.20995 to 120.05402, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 120.3985 - mae: 80.9002 - val_loss: 120.0540 - val_mae: 79.1097\n",
      "Epoch 151/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 121.7400 - mae: 81.6371\n",
      "Epoch 151: val_loss did not improve from 120.05402\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 120.2850 - mae: 80.7082 - val_loss: 120.5986 - val_mae: 81.4123\n",
      "Epoch 152/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 124.1477 - mae: 83.4192\n",
      "Epoch 152: val_loss did not improve from 120.05402\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 120.5231 - mae: 80.8460 - val_loss: 120.8991 - val_mae: 81.7659\n",
      "Epoch 153/400\n",
      "7/7 [==============================] - ETA: 0s - loss: 120.4467 - mae: 80.4585\n",
      "Epoch 153: val_loss did not improve from 120.05402\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 120.4467 - mae: 80.4585 - val_loss: 120.6255 - val_mae: 81.3999\n",
      "Epoch 154/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 124.0593 - mae: 84.6346\n",
      "Epoch 154: val_loss did not improve from 120.05402\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 120.4403 - mae: 80.8465 - val_loss: 120.8042 - val_mae: 82.0139\n",
      "Epoch 155/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 116.8958 - mae: 82.4218\n",
      "Epoch 155: val_loss did not improve from 120.05402\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 120.0970 - mae: 80.4239 - val_loss: 120.7198 - val_mae: 81.5692\n",
      "Epoch 156/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 116.7684 - mae: 80.8752\n",
      "Epoch 156: val_loss improved from 120.05402 to 119.71328, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 120.0398 - mae: 80.5983 - val_loss: 119.7133 - val_mae: 79.3340\n",
      "Epoch 157/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 122.1816 - mae: 80.2794\n",
      "Epoch 157: val_loss improved from 119.71328 to 119.55636, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 119.7505 - mae: 80.4536 - val_loss: 119.5564 - val_mae: 78.6704\n",
      "Epoch 158/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 122.6257 - mae: 79.2275\n",
      "Epoch 158: val_loss improved from 119.55636 to 119.34953, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 119.8687 - mae: 80.3363 - val_loss: 119.3495 - val_mae: 78.0461\n",
      "Epoch 159/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 121.2609 - mae: 80.8599\n",
      "Epoch 159: val_loss improved from 119.34953 to 119.24039, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 119.7256 - mae: 80.4016 - val_loss: 119.2404 - val_mae: 78.1814\n",
      "Epoch 160/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.6550 - mae: 75.3994\n",
      "Epoch 160: val_loss did not improve from 119.24039\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 119.5658 - mae: 80.0603 - val_loss: 120.1468 - val_mae: 80.7710\n",
      "Epoch 161/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 122.7561 - mae: 82.8727\n",
      "Epoch 161: val_loss improved from 119.24039 to 119.20656, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 119.4435 - mae: 80.2112 - val_loss: 119.2066 - val_mae: 78.2949\n",
      "Epoch 162/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 120.3142 - mae: 79.0922\n",
      "Epoch 162: val_loss did not improve from 119.20656\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 119.5362 - mae: 80.7782 - val_loss: 119.8367 - val_mae: 76.4558\n",
      "Epoch 163/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 115.3614 - mae: 75.3353\n",
      "Epoch 163: val_loss did not improve from 119.20656\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 120.4583 - mae: 80.5129 - val_loss: 119.3968 - val_mae: 77.2642\n",
      "Epoch 164/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 123.6281 - mae: 80.5359\n",
      "Epoch 164: val_loss improved from 119.20656 to 119.02193, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 119.8511 - mae: 80.2092 - val_loss: 119.0219 - val_mae: 77.9540\n",
      "Epoch 165/400\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 118.8764 - mae: 78.8966\n",
      "Epoch 165: val_loss did not improve from 119.02193\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 119.1299 - mae: 79.1789 - val_loss: 121.2280 - val_mae: 83.1544\n",
      "Epoch 166/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 121.1262 - mae: 84.7146\n",
      "Epoch 166: val_loss did not improve from 119.02193\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 119.6288 - mae: 79.8828 - val_loss: 119.8035 - val_mae: 80.8032\n",
      "Epoch 167/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 122.2427 - mae: 82.7011\n",
      "Epoch 167: val_loss improved from 119.02193 to 119.00178, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 119.4972 - mae: 80.6975 - val_loss: 119.0018 - val_mae: 76.7192\n",
      "Epoch 168/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 127.1572 - mae: 81.9281\n",
      "Epoch 168: val_loss did not improve from 119.00178\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 119.4491 - mae: 80.5666 - val_loss: 119.1691 - val_mae: 76.5598\n",
      "Epoch 169/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 129.2207 - mae: 83.9684\n",
      "Epoch 169: val_loss improved from 119.00178 to 118.89506, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 119.2491 - mae: 80.2424 - val_loss: 118.8951 - val_mae: 76.8182\n",
      "Epoch 170/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.7714 - mae: 74.7854\n",
      "Epoch 170: val_loss did not improve from 118.89506\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 119.6359 - mae: 80.0835 - val_loss: 119.2256 - val_mae: 80.1992\n",
      "Epoch 171/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 123.0021 - mae: 83.1156\n",
      "Epoch 171: val_loss did not improve from 118.89506\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 118.7987 - mae: 79.2434 - val_loss: 119.3582 - val_mae: 80.0946\n",
      "Epoch 172/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.3008 - mae: 76.3782\n",
      "Epoch 172: val_loss did not improve from 118.89506\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 118.8946 - mae: 79.2565 - val_loss: 119.3597 - val_mae: 80.3702\n",
      "Epoch 173/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 125.0354 - mae: 85.8312\n",
      "Epoch 173: val_loss did not improve from 118.89506\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 118.6688 - mae: 78.9800 - val_loss: 119.2519 - val_mae: 79.8880\n",
      "Epoch 174/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 116.0581 - mae: 79.2230\n",
      "Epoch 174: val_loss improved from 118.89506 to 118.67345, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 118.9446 - mae: 79.7522 - val_loss: 118.6734 - val_mae: 78.6906\n",
      "Epoch 175/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 126.7011 - mae: 84.0289\n",
      "Epoch 175: val_loss did not improve from 118.67345\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 118.7535 - mae: 79.6219 - val_loss: 119.3436 - val_mae: 80.6938\n",
      "Epoch 176/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.5819 - mae: 77.7235\n",
      "Epoch 176: val_loss improved from 118.67345 to 118.37207, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 118.6548 - mae: 79.6530 - val_loss: 118.3721 - val_mae: 77.9360\n",
      "Epoch 177/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 119.1003 - mae: 80.5937\n",
      "Epoch 177: val_loss improved from 118.37207 to 118.12170, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 118.3516 - mae: 79.3753 - val_loss: 118.1217 - val_mae: 78.0493\n",
      "Epoch 178/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 115.3659 - mae: 75.9405\n",
      "Epoch 178: val_loss did not improve from 118.12170\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 118.3018 - mae: 78.9556 - val_loss: 118.1309 - val_mae: 77.9270\n",
      "Epoch 179/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 116.7669 - mae: 77.0346\n",
      "Epoch 179: val_loss improved from 118.12170 to 117.97319, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 117.9776 - mae: 79.0780 - val_loss: 117.9732 - val_mae: 77.2663\n",
      "Epoch 180/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 114.0358 - mae: 75.8216\n",
      "Epoch 180: val_loss did not improve from 117.97319\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 118.1244 - mae: 79.1880 - val_loss: 118.1450 - val_mae: 75.7503\n",
      "Epoch 181/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 121.5542 - mae: 77.7372\n",
      "Epoch 181: val_loss improved from 117.97319 to 117.97191, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 119.0374 - mae: 79.7182 - val_loss: 117.9719 - val_mae: 75.9279\n",
      "Epoch 182/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 111.4207 - mae: 73.8955\n",
      "Epoch 182: val_loss did not improve from 117.97191\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 118.6367 - mae: 78.9777 - val_loss: 118.1763 - val_mae: 78.6650\n",
      "Epoch 183/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 123.7738 - mae: 83.0875\n",
      "Epoch 183: val_loss did not improve from 117.97191\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 118.5753 - mae: 78.4808 - val_loss: 118.8398 - val_mae: 80.5062\n",
      "Epoch 184/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 124.9853 - mae: 86.5052\n",
      "Epoch 184: val_loss did not improve from 117.97191\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 117.9747 - mae: 78.3131 - val_loss: 118.2958 - val_mae: 78.9530\n",
      "Epoch 185/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 125.6051 - mae: 83.8292\n",
      "Epoch 185: val_loss improved from 117.97191 to 117.92822, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 117.6726 - mae: 78.5023 - val_loss: 117.9282 - val_mae: 77.8406\n",
      "Epoch 186/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 120.6711 - mae: 77.6633\n",
      "Epoch 186: val_loss improved from 117.92822 to 117.62412, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 117.5228 - mae: 78.3781 - val_loss: 117.6241 - val_mae: 77.5385\n",
      "Epoch 187/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 108.0953 - mae: 73.2820\n",
      "Epoch 187: val_loss did not improve from 117.62412\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 117.3633 - mae: 78.4228 - val_loss: 117.7379 - val_mae: 77.5115\n",
      "Epoch 188/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.9652 - mae: 75.3114\n",
      "Epoch 188: val_loss improved from 117.62412 to 117.18397, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 117.3646 - mae: 78.3727 - val_loss: 117.1840 - val_mae: 76.0510\n",
      "Epoch 189/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 125.3662 - mae: 80.5332\n",
      "Epoch 189: val_loss did not improve from 117.18397\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 117.3949 - mae: 78.6256 - val_loss: 117.7453 - val_mae: 75.0552\n",
      "Epoch 190/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.7234 - mae: 73.6829\n",
      "Epoch 190: val_loss did not improve from 117.18397\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 118.0337 - mae: 78.4672 - val_loss: 117.6164 - val_mae: 76.9488\n",
      "Epoch 191/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.2602 - mae: 75.5815\n",
      "Epoch 191: val_loss did not improve from 117.18397\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 117.6551 - mae: 78.1221 - val_loss: 118.6423 - val_mae: 80.5874\n",
      "Epoch 192/400\n",
      "2/7 [=======>......................] - ETA: 0s - loss: 114.1402 - mae: 77.5136\n",
      "Epoch 192: val_loss improved from 117.18397 to 117.10635, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 117.3713 - mae: 78.4573 - val_loss: 117.1064 - val_mae: 77.0634\n",
      "Epoch 193/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 117.8584 - mae: 77.0549\n",
      "Epoch 193: val_loss did not improve from 117.10635\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 116.9340 - mae: 77.9442 - val_loss: 117.3343 - val_mae: 78.0143\n",
      "Epoch 194/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.3398 - mae: 77.9615\n",
      "Epoch 194: val_loss did not improve from 117.10635\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 117.1264 - mae: 77.9424 - val_loss: 117.6532 - val_mae: 78.4680\n",
      "Epoch 195/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 120.0995 - mae: 80.8323\n",
      "Epoch 195: val_loss did not improve from 117.10635\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 117.0537 - mae: 77.7589 - val_loss: 117.9587 - val_mae: 79.4540\n",
      "Epoch 196/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 112.9562 - mae: 77.5696\n",
      "Epoch 196: val_loss did not improve from 117.10635\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 116.9086 - mae: 77.6345 - val_loss: 117.9821 - val_mae: 79.4637\n",
      "Epoch 197/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 120.1795 - mae: 80.1732\n",
      "Epoch 197: val_loss improved from 117.10635 to 116.93916, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 116.8788 - mae: 78.2592 - val_loss: 116.9392 - val_mae: 76.8047\n",
      "Epoch 198/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 116.2256 - mae: 78.6279\n",
      "Epoch 198: val_loss did not improve from 116.93916\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 116.5604 - mae: 77.7000 - val_loss: 117.4864 - val_mae: 78.5218\n",
      "Epoch 199/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 114.8405 - mae: 76.1679\n",
      "Epoch 199: val_loss improved from 116.93916 to 116.80286, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 116.9012 - mae: 77.8668 - val_loss: 116.8029 - val_mae: 76.5980\n",
      "Epoch 200/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 115.7497 - mae: 78.4138\n",
      "Epoch 200: val_loss improved from 116.80286 to 116.51162, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 116.6371 - mae: 78.4284 - val_loss: 116.5116 - val_mae: 75.7527\n",
      "Epoch 201/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 110.3417 - mae: 72.6466\n",
      "Epoch 201: val_loss did not improve from 116.51162\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 116.2672 - mae: 78.2498 - val_loss: 116.9143 - val_mae: 76.8408\n",
      "Epoch 202/400\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 116.1447 - mae: 77.1493\n",
      "Epoch 202: val_loss did not improve from 116.51162\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 116.5620 - mae: 77.2690 - val_loss: 117.0844 - val_mae: 77.8902\n",
      "Epoch 203/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 117.1411 - mae: 78.0894\n",
      "Epoch 203: val_loss improved from 116.51162 to 116.31066, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 116.3348 - mae: 77.5579 - val_loss: 116.3107 - val_mae: 75.9303\n",
      "Epoch 204/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 115.9151 - mae: 76.9185\n",
      "Epoch 204: val_loss did not improve from 116.31066\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 116.3105 - mae: 77.1959 - val_loss: 116.7182 - val_mae: 77.3790\n",
      "Epoch 205/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 114.6652 - mae: 79.2817\n",
      "Epoch 205: val_loss did not improve from 116.31066\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 116.6215 - mae: 77.5998 - val_loss: 116.7306 - val_mae: 77.5971\n",
      "Epoch 206/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 109.3499 - mae: 74.1793\n",
      "Epoch 206: val_loss improved from 116.31066 to 116.16894, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 116.2929 - mae: 77.6557 - val_loss: 116.1689 - val_mae: 75.3986\n",
      "Epoch 207/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 117.2299 - mae: 79.9967\n",
      "Epoch 207: val_loss improved from 116.16894 to 116.15592, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 116.1060 - mae: 77.6564 - val_loss: 116.1559 - val_mae: 75.4817\n",
      "Epoch 208/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 114.2127 - mae: 75.3857\n",
      "Epoch 208: val_loss did not improve from 116.15592\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 115.9896 - mae: 77.0981 - val_loss: 116.3310 - val_mae: 76.0996\n",
      "Epoch 209/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 120.1405 - mae: 79.6069\n",
      "Epoch 209: val_loss improved from 116.15592 to 115.98410, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 115.7935 - mae: 77.1935 - val_loss: 115.9841 - val_mae: 74.7440\n",
      "Epoch 210/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 120.2108 - mae: 77.2804\n",
      "Epoch 210: val_loss did not improve from 115.98410\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 115.9925 - mae: 77.3445 - val_loss: 116.0874 - val_mae: 75.2716\n",
      "Epoch 211/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 122.1047 - mae: 79.5705\n",
      "Epoch 211: val_loss did not improve from 115.98410\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 115.9607 - mae: 77.2389 - val_loss: 116.0083 - val_mae: 74.6863\n",
      "Epoch 212/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 115.7262 - mae: 75.2865\n",
      "Epoch 212: val_loss did not improve from 115.98410\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 115.9311 - mae: 77.4046 - val_loss: 116.1212 - val_mae: 74.8177\n",
      "Epoch 213/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.3295 - mae: 73.1231\n",
      "Epoch 213: val_loss improved from 115.98410 to 115.94152, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 116.4420 - mae: 77.8532 - val_loss: 115.9415 - val_mae: 75.3836\n",
      "Epoch 214/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.9790 - mae: 74.3810\n",
      "Epoch 214: val_loss did not improve from 115.94152\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 116.2330 - mae: 76.9459 - val_loss: 117.3766 - val_mae: 79.4397\n",
      "Epoch 215/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.0776 - mae: 78.4028\n",
      "Epoch 215: val_loss did not improve from 115.94152\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 115.9130 - mae: 76.3311 - val_loss: 116.8422 - val_mae: 78.7845\n",
      "Epoch 216/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 118.1387 - mae: 80.1333\n",
      "Epoch 216: val_loss improved from 115.94152 to 115.82858, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 115.6111 - mae: 76.9193 - val_loss: 115.8286 - val_mae: 76.3888\n",
      "Epoch 217/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 119.8257 - mae: 80.7560\n",
      "Epoch 217: val_loss improved from 115.82858 to 115.74677, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 115.4320 - mae: 76.8290 - val_loss: 115.7468 - val_mae: 75.5750\n",
      "Epoch 218/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 110.3759 - mae: 72.0074\n",
      "Epoch 218: val_loss did not improve from 115.74677\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 115.4071 - mae: 77.1544 - val_loss: 115.8638 - val_mae: 74.6981\n",
      "Epoch 219/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 123.7524 - mae: 80.2570\n",
      "Epoch 219: val_loss did not improve from 115.74677\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 115.6044 - mae: 77.5117 - val_loss: 115.8442 - val_mae: 73.9699\n",
      "Epoch 220/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 121.8390 - mae: 78.7457\n",
      "Epoch 220: val_loss improved from 115.74677 to 115.24267, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 115.5566 - mae: 77.0423 - val_loss: 115.2427 - val_mae: 74.4543\n",
      "Epoch 221/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.0091 - mae: 74.0450\n",
      "Epoch 221: val_loss did not improve from 115.24267\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 115.2090 - mae: 76.5979 - val_loss: 115.2522 - val_mae: 74.2775\n",
      "Epoch 222/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 119.1092 - mae: 76.5912\n",
      "Epoch 222: val_loss did not improve from 115.24267\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 115.3016 - mae: 76.0542 - val_loss: 116.2234 - val_mae: 77.6022\n",
      "Epoch 223/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 114.6409 - mae: 77.3432\n",
      "Epoch 223: val_loss improved from 115.24267 to 115.03455, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 115.0855 - mae: 76.6713 - val_loss: 115.0346 - val_mae: 75.1720\n",
      "Epoch 224/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 119.8541 - mae: 78.9397\n",
      "Epoch 224: val_loss did not improve from 115.03455\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 114.9293 - mae: 76.0929 - val_loss: 115.5023 - val_mae: 76.6797\n",
      "Epoch 225/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 119.5583 - mae: 81.4856\n",
      "Epoch 225: val_loss did not improve from 115.03455\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 115.4799 - mae: 76.3335 - val_loss: 117.1941 - val_mae: 80.0484\n",
      "Epoch 226/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 119.1132 - mae: 81.4870\n",
      "Epoch 226: val_loss improved from 115.03455 to 114.84283, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 117.2802 - mae: 78.6822 - val_loss: 114.8428 - val_mae: 74.1919\n",
      "Epoch 227/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.2316 - mae: 75.1219\n",
      "Epoch 227: val_loss did not improve from 114.84283\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 115.6623 - mae: 78.4679 - val_loss: 116.1984 - val_mae: 72.7798\n",
      "Epoch 228/400\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 115.9072 - mae: 77.8054\n",
      "Epoch 228: val_loss did not improve from 114.84283\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 116.0310 - mae: 77.6819 - val_loss: 115.1067 - val_mae: 73.3925\n",
      "Epoch 229/400\n",
      "7/7 [==============================] - ETA: 0s - loss: 115.1413 - mae: 75.8753\n",
      "Epoch 229: val_loss did not improve from 114.84283\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 115.1413 - mae: 75.8753 - val_loss: 115.0355 - val_mae: 75.9506\n",
      "Epoch 230/400\n",
      "7/7 [==============================] - ETA: 0s - loss: 114.3350 - mae: 75.7082\n",
      "Epoch 230: val_loss improved from 114.84283 to 114.80104, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 114.3350 - mae: 75.7082 - val_loss: 114.8010 - val_mae: 74.2167\n",
      "Epoch 231/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 104.5909 - mae: 68.2053\n",
      "Epoch 231: val_loss improved from 114.80104 to 114.73197, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 114.4042 - mae: 76.2633 - val_loss: 114.7320 - val_mae: 74.6384\n",
      "Epoch 232/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.1252 - mae: 72.2041\n",
      "Epoch 232: val_loss did not improve from 114.73197\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 114.7030 - mae: 76.3767 - val_loss: 114.8436 - val_mae: 74.5752\n",
      "Epoch 233/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 122.0359 - mae: 81.2211\n",
      "Epoch 233: val_loss improved from 114.73197 to 114.61790, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 114.4910 - mae: 75.9185 - val_loss: 114.6179 - val_mae: 74.5993\n",
      "Epoch 234/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 114.1046 - mae: 75.2077\n",
      "Epoch 234: val_loss did not improve from 114.61790\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 114.2275 - mae: 75.3050 - val_loss: 114.8035 - val_mae: 75.8725\n",
      "Epoch 235/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 115.5818 - mae: 75.9435\n",
      "Epoch 235: val_loss did not improve from 114.61790\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 114.1600 - mae: 75.4711 - val_loss: 114.7400 - val_mae: 75.9730\n",
      "Epoch 236/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 110.6386 - mae: 74.4094\n",
      "Epoch 236: val_loss did not improve from 114.61790\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 114.2096 - mae: 76.1199 - val_loss: 114.8930 - val_mae: 76.0467\n",
      "Epoch 237/400\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 113.7340 - mae: 75.7364\n",
      "Epoch 237: val_loss improved from 114.61790 to 114.40009, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 113.9644 - mae: 75.8016 - val_loss: 114.4001 - val_mae: 75.2165\n",
      "Epoch 238/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 110.9112 - mae: 74.4510\n",
      "Epoch 238: val_loss did not improve from 114.40009\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 113.9933 - mae: 75.5406 - val_loss: 115.6428 - val_mae: 78.0727\n",
      "Epoch 239/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 111.8988 - mae: 76.2981\n",
      "Epoch 239: val_loss did not improve from 114.40009\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 114.1650 - mae: 75.6327 - val_loss: 114.8449 - val_mae: 76.0884\n",
      "Epoch 240/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 120.2302 - mae: 80.1432\n",
      "Epoch 240: val_loss did not improve from 114.40009\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 114.0285 - mae: 75.1852 - val_loss: 114.5572 - val_mae: 75.9075\n",
      "Epoch 241/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 117.7841 - mae: 77.7938\n",
      "Epoch 241: val_loss did not improve from 114.40009\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 113.7930 - mae: 75.2418 - val_loss: 114.5620 - val_mae: 76.3754\n",
      "Epoch 242/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 111.8664 - mae: 73.9079\n",
      "Epoch 242: val_loss did not improve from 114.40009\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 113.9026 - mae: 75.5203 - val_loss: 115.0178 - val_mae: 77.2155\n",
      "Epoch 243/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 111.6531 - mae: 74.3852\n",
      "Epoch 243: val_loss did not improve from 114.40009\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 114.2178 - mae: 75.3661 - val_loss: 115.3729 - val_mae: 77.4973\n",
      "Epoch 244/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 111.4609 - mae: 75.9345\n",
      "Epoch 244: val_loss did not improve from 114.40009\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 114.5270 - mae: 75.0750 - val_loss: 117.8951 - val_mae: 82.0649\n",
      "Epoch 245/400\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 114.6955 - mae: 76.5432\n",
      "Epoch 245: val_loss improved from 114.40009 to 113.80997, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 114.4188 - mae: 76.2670 - val_loss: 113.8100 - val_mae: 74.4647\n",
      "Epoch 246/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 112.2278 - mae: 76.6894\n",
      "Epoch 246: val_loss did not improve from 113.80997\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 113.5779 - mae: 76.2344 - val_loss: 113.9510 - val_mae: 72.9866\n",
      "Epoch 247/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 108.6353 - mae: 70.0965\n",
      "Epoch 247: val_loss did not improve from 113.80997\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 113.2670 - mae: 74.5825 - val_loss: 114.7103 - val_mae: 76.3644\n",
      "Epoch 248/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 118.7966 - mae: 79.6872\n",
      "Epoch 248: val_loss improved from 113.80997 to 113.57391, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 113.4449 - mae: 75.3485 - val_loss: 113.5739 - val_mae: 74.2585\n",
      "Epoch 249/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 112.5814 - mae: 77.7519\n",
      "Epoch 249: val_loss did not improve from 113.57391\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 113.0194 - mae: 74.9390 - val_loss: 114.2124 - val_mae: 76.2417\n",
      "Epoch 250/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 108.7835 - mae: 74.0368\n",
      "Epoch 250: val_loss did not improve from 113.57391\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 113.1880 - mae: 75.1031 - val_loss: 113.6820 - val_mae: 75.0017\n",
      "Epoch 251/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.1168 - mae: 74.2196\n",
      "Epoch 251: val_loss did not improve from 113.57391\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 112.9922 - mae: 74.8155 - val_loss: 113.5881 - val_mae: 74.8848\n",
      "Epoch 252/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 105.0666 - mae: 70.2600\n",
      "Epoch 252: val_loss improved from 113.57391 to 113.32354, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 112.9521 - mae: 75.2490 - val_loss: 113.3235 - val_mae: 72.9594\n",
      "Epoch 253/400\n",
      "7/7 [==============================] - ETA: 0s - loss: 113.0536 - mae: 74.7558\n",
      "Epoch 253: val_loss improved from 113.32354 to 113.16050, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 113.0536 - mae: 74.7558 - val_loss: 113.1605 - val_mae: 73.5130\n",
      "Epoch 254/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 108.0926 - mae: 71.4903\n",
      "Epoch 254: val_loss did not improve from 113.16050\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 112.8361 - mae: 74.1269 - val_loss: 114.3862 - val_mae: 76.8252\n",
      "Epoch 255/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 114.0116 - mae: 78.1429\n",
      "Epoch 255: val_loss did not improve from 113.16050\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 113.0316 - mae: 74.7188 - val_loss: 113.9091 - val_mae: 75.7721\n",
      "Epoch 256/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 115.6178 - mae: 77.7793\n",
      "Epoch 256: val_loss did not improve from 113.16050\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 113.1311 - mae: 74.8844 - val_loss: 113.2895 - val_mae: 74.4887\n",
      "Epoch 257/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 114.1681 - mae: 77.5336\n",
      "Epoch 257: val_loss did not improve from 113.16050\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 112.8336 - mae: 74.7128 - val_loss: 113.3328 - val_mae: 74.8157\n",
      "Epoch 258/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 111.0929 - mae: 73.3391\n",
      "Epoch 258: val_loss improved from 113.16050 to 113.02742, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 112.6312 - mae: 75.1205 - val_loss: 113.0274 - val_mae: 72.9503\n",
      "Epoch 259/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 111.3759 - mae: 73.3154\n",
      "Epoch 259: val_loss improved from 113.02742 to 112.71797, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 112.6519 - mae: 74.5640 - val_loss: 112.7180 - val_mae: 72.8097\n",
      "Epoch 260/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 116.5750 - mae: 76.3432\n",
      "Epoch 260: val_loss did not improve from 112.71797\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 112.5565 - mae: 74.6350 - val_loss: 112.9899 - val_mae: 73.2285\n",
      "Epoch 261/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 106.5727 - mae: 69.6839\n",
      "Epoch 261: val_loss improved from 112.71797 to 112.61370, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 112.7902 - mae: 74.6377 - val_loss: 112.6137 - val_mae: 73.3586\n",
      "Epoch 262/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 110.2232 - mae: 71.8566\n",
      "Epoch 262: val_loss improved from 112.61370 to 112.37868, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 112.1643 - mae: 74.3590 - val_loss: 112.3787 - val_mae: 72.9287\n",
      "Epoch 263/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 108.2521 - mae: 70.4829\n",
      "Epoch 263: val_loss improved from 112.37868 to 112.30978, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 112.0017 - mae: 74.3444 - val_loss: 112.3098 - val_mae: 73.1422\n",
      "Epoch 264/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 108.6096 - mae: 73.8272\n",
      "Epoch 264: val_loss did not improve from 112.30978\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 111.9215 - mae: 73.6852 - val_loss: 112.5553 - val_mae: 73.8508\n",
      "Epoch 265/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 103.7730 - mae: 69.2385\n",
      "Epoch 265: val_loss did not improve from 112.30978\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 111.7225 - mae: 74.1462 - val_loss: 112.5484 - val_mae: 72.3596\n",
      "Epoch 266/400\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 112.5367 - mae: 74.8265\n",
      "Epoch 266: val_loss improved from 112.30978 to 112.25397, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 112.1554 - mae: 74.4874 - val_loss: 112.2540 - val_mae: 73.0230\n",
      "Epoch 267/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.3740 - mae: 75.5995\n",
      "Epoch 267: val_loss did not improve from 112.25397\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 111.6760 - mae: 73.5332 - val_loss: 112.9619 - val_mae: 74.6196\n",
      "Epoch 268/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 106.3891 - mae: 70.6887\n",
      "Epoch 268: val_loss improved from 112.25397 to 111.95522, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 111.8346 - mae: 73.8474 - val_loss: 111.9552 - val_mae: 72.8944\n",
      "Epoch 269/400\n",
      "2/7 [=======>......................] - ETA: 0s - loss: 111.9548 - mae: 74.2165\n",
      "Epoch 269: val_loss improved from 111.95522 to 111.76061, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 111.8498 - mae: 74.0297 - val_loss: 111.7606 - val_mae: 72.7818\n",
      "Epoch 270/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 108.2020 - mae: 70.6508\n",
      "Epoch 270: val_loss did not improve from 111.76061\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 111.6133 - mae: 74.1900 - val_loss: 112.0981 - val_mae: 71.2984\n",
      "Epoch 271/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 110.0522 - mae: 70.7872\n",
      "Epoch 271: val_loss did not improve from 111.76061\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 111.9974 - mae: 74.2172 - val_loss: 112.2337 - val_mae: 71.4313\n",
      "Epoch 272/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 109.9201 - mae: 69.4662\n",
      "Epoch 272: val_loss did not improve from 111.76061\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 111.8443 - mae: 73.8434 - val_loss: 112.4615 - val_mae: 74.9365\n",
      "Epoch 273/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 112.4360 - mae: 76.6486\n",
      "Epoch 273: val_loss did not improve from 111.76061\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 111.6958 - mae: 73.7070 - val_loss: 112.8474 - val_mae: 73.8469\n",
      "Epoch 274/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 115.3724 - mae: 76.0964\n",
      "Epoch 274: val_loss did not improve from 111.76061\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 112.1133 - mae: 74.1276 - val_loss: 111.8690 - val_mae: 71.7887\n",
      "Epoch 275/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 114.4265 - mae: 73.4756\n",
      "Epoch 275: val_loss improved from 111.76061 to 111.43240, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 111.5041 - mae: 73.7332 - val_loss: 111.4324 - val_mae: 72.6196\n",
      "Epoch 276/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 120.7934 - mae: 78.2618\n",
      "Epoch 276: val_loss did not improve from 111.43240\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 110.9320 - mae: 72.7901 - val_loss: 112.0686 - val_mae: 74.0439\n",
      "Epoch 277/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 111.6959 - mae: 73.1228\n",
      "Epoch 277: val_loss did not improve from 111.43240\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 110.9643 - mae: 73.1984 - val_loss: 111.6094 - val_mae: 73.6285\n",
      "Epoch 278/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 102.7944 - mae: 71.0724\n",
      "Epoch 278: val_loss improved from 111.43240 to 111.36076, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 111.0655 - mae: 73.6489 - val_loss: 111.3608 - val_mae: 72.4599\n",
      "Epoch 279/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 112.7981 - mae: 72.0542\n",
      "Epoch 279: val_loss did not improve from 111.36076\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 111.0673 - mae: 72.7344 - val_loss: 112.0356 - val_mae: 74.4311\n",
      "Epoch 280/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 112.5854 - mae: 76.6798\n",
      "Epoch 280: val_loss did not improve from 111.36076\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 110.9418 - mae: 73.2748 - val_loss: 112.1406 - val_mae: 73.8441\n",
      "Epoch 281/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 110.7405 - mae: 73.9860\n",
      "Epoch 281: val_loss did not improve from 111.36076\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 110.8210 - mae: 73.3176 - val_loss: 111.8947 - val_mae: 73.7756\n",
      "Epoch 282/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 117.7138 - mae: 77.9183\n",
      "Epoch 282: val_loss improved from 111.36076 to 110.87441, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 111.1215 - mae: 73.7592 - val_loss: 110.8744 - val_mae: 71.7361\n",
      "Epoch 283/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 110.8394 - mae: 70.3359\n",
      "Epoch 283: val_loss did not improve from 110.87441\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 110.8409 - mae: 73.5696 - val_loss: 111.7259 - val_mae: 70.4413\n",
      "Epoch 284/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.5677 - mae: 67.9422\n",
      "Epoch 284: val_loss did not improve from 110.87441\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 111.2418 - mae: 73.4244 - val_loss: 111.2308 - val_mae: 71.6343\n",
      "Epoch 285/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 108.8422 - mae: 71.4424\n",
      "Epoch 285: val_loss improved from 110.87441 to 110.58249, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 110.9017 - mae: 73.2669 - val_loss: 110.5825 - val_mae: 71.8534\n",
      "Epoch 286/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 111.0493 - mae: 73.3291\n",
      "Epoch 286: val_loss did not improve from 110.58249\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 110.1707 - mae: 72.3915 - val_loss: 112.4052 - val_mae: 75.7311\n",
      "Epoch 287/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 102.5953 - mae: 70.4633\n",
      "Epoch 287: val_loss did not improve from 110.58249\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 110.8722 - mae: 73.3012 - val_loss: 111.0688 - val_mae: 73.0063\n",
      "Epoch 288/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 116.0830 - mae: 77.6008\n",
      "Epoch 288: val_loss improved from 110.58249 to 110.49481, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 110.2360 - mae: 73.1498 - val_loss: 110.4948 - val_mae: 70.9058\n",
      "Epoch 289/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 104.9447 - mae: 67.8828\n",
      "Epoch 289: val_loss improved from 110.49481 to 110.42531, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 110.1052 - mae: 73.0044 - val_loss: 110.4253 - val_mae: 71.6999\n",
      "Epoch 290/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 106.0108 - mae: 68.5441\n",
      "Epoch 290: val_loss did not improve from 110.42531\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 110.2672 - mae: 72.9911 - val_loss: 110.9496 - val_mae: 70.4150\n",
      "Epoch 291/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 103.2667 - mae: 67.1743\n",
      "Epoch 291: val_loss improved from 110.42531 to 110.39238, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 110.5908 - mae: 72.7992 - val_loss: 110.3924 - val_mae: 71.4745\n",
      "Epoch 292/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 118.3834 - mae: 77.1769\n",
      "Epoch 292: val_loss did not improve from 110.39238\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 110.0751 - mae: 72.3535 - val_loss: 110.6471 - val_mae: 73.0310\n",
      "Epoch 293/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.5090 - mae: 76.9719\n",
      "Epoch 293: val_loss did not improve from 110.39238\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 109.9932 - mae: 72.7622 - val_loss: 110.5971 - val_mae: 72.3683\n",
      "Epoch 294/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.8653 - mae: 71.5155\n",
      "Epoch 294: val_loss did not improve from 110.39238\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 110.0458 - mae: 72.4753 - val_loss: 110.5143 - val_mae: 72.4097\n",
      "Epoch 295/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.5202 - mae: 72.2505\n",
      "Epoch 295: val_loss improved from 110.39238 to 110.16947, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 109.7077 - mae: 72.2204 - val_loss: 110.1695 - val_mae: 71.6985\n",
      "Epoch 296/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 111.1579 - mae: 73.1419\n",
      "Epoch 296: val_loss improved from 110.16947 to 110.16413, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 109.7641 - mae: 72.5216 - val_loss: 110.1641 - val_mae: 70.5196\n",
      "Epoch 297/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.6637 - mae: 72.6310\n",
      "Epoch 297: val_loss improved from 110.16413 to 110.02093, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 110.0531 - mae: 72.8024 - val_loss: 110.0209 - val_mae: 70.1740\n",
      "Epoch 298/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.9801 - mae: 72.0587\n",
      "Epoch 298: val_loss improved from 110.02093 to 109.73354, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 109.9653 - mae: 72.8862 - val_loss: 109.7335 - val_mae: 70.4781\n",
      "Epoch 299/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 118.4274 - mae: 75.7158\n",
      "Epoch 299: val_loss did not improve from 109.73354\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 109.5746 - mae: 72.5192 - val_loss: 109.9927 - val_mae: 70.4632\n",
      "Epoch 300/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 109.4766 - mae: 69.9921\n",
      "Epoch 300: val_loss did not improve from 109.73354\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 109.1949 - mae: 72.1791 - val_loss: 109.8811 - val_mae: 71.3284\n",
      "Epoch 301/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 109.3664 - mae: 72.3393\n",
      "Epoch 301: val_loss improved from 109.73354 to 109.64423, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 109.3346 - mae: 72.2919 - val_loss: 109.6442 - val_mae: 70.2831\n",
      "Epoch 302/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.5746 - mae: 69.7656\n",
      "Epoch 302: val_loss did not improve from 109.64423\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 109.1230 - mae: 72.0386 - val_loss: 109.9366 - val_mae: 69.8629\n",
      "Epoch 303/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 103.8444 - mae: 68.4756\n",
      "Epoch 303: val_loss did not improve from 109.64423\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 109.7904 - mae: 72.6481 - val_loss: 110.5288 - val_mae: 69.5572\n",
      "Epoch 304/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 112.0133 - mae: 71.2539\n",
      "Epoch 304: val_loss improved from 109.64423 to 109.51285, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 109.9296 - mae: 72.4340 - val_loss: 109.5128 - val_mae: 69.5872\n",
      "Epoch 305/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 102.0303 - mae: 65.3918\n",
      "Epoch 305: val_loss did not improve from 109.51285\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 109.0502 - mae: 71.6458 - val_loss: 110.1735 - val_mae: 73.2494\n",
      "Epoch 306/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.1441 - mae: 73.6611\n",
      "Epoch 306: val_loss did not improve from 109.51285\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 109.0466 - mae: 71.6722 - val_loss: 110.8735 - val_mae: 74.1860\n",
      "Epoch 307/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.6899 - mae: 73.5278\n",
      "Epoch 307: val_loss did not improve from 109.51285\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 109.3562 - mae: 71.8238 - val_loss: 109.7097 - val_mae: 71.5812\n",
      "Epoch 308/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 109.1658 - mae: 71.6802\n",
      "Epoch 308: val_loss did not improve from 109.51285\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 108.8270 - mae: 71.1792 - val_loss: 109.9435 - val_mae: 72.6021\n",
      "Epoch 309/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 105.2370 - mae: 71.6235\n",
      "Epoch 309: val_loss improved from 109.51285 to 109.21783, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 108.6325 - mae: 71.2973 - val_loss: 109.2178 - val_mae: 71.0472\n",
      "Epoch 310/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 116.8427 - mae: 76.9352\n",
      "Epoch 310: val_loss improved from 109.21783 to 108.91731, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 108.4118 - mae: 71.3220 - val_loss: 108.9173 - val_mae: 70.0903\n",
      "Epoch 311/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 109.8535 - mae: 71.1709\n",
      "Epoch 311: val_loss did not improve from 108.91731\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 108.4706 - mae: 71.1987 - val_loss: 109.5577 - val_mae: 72.2115\n",
      "Epoch 312/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 112.4855 - mae: 73.6017\n",
      "Epoch 312: val_loss did not improve from 108.91731\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 108.3787 - mae: 71.4524 - val_loss: 108.9853 - val_mae: 70.6112\n",
      "Epoch 313/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 108.6621 - mae: 72.2391\n",
      "Epoch 313: val_loss did not improve from 108.91731\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 108.1887 - mae: 70.9683 - val_loss: 109.0184 - val_mae: 71.2869\n",
      "Epoch 314/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 109.9499 - mae: 71.4498\n",
      "Epoch 314: val_loss did not improve from 108.91731\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 108.1798 - mae: 71.1058 - val_loss: 108.9246 - val_mae: 71.2980\n",
      "Epoch 315/400\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 107.6779 - mae: 71.7928\n",
      "Epoch 315: val_loss did not improve from 108.91731\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 108.6472 - mae: 71.5747 - val_loss: 108.9398 - val_mae: 71.1701\n",
      "Epoch 316/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 106.8958 - mae: 70.0956\n",
      "Epoch 316: val_loss did not improve from 108.91731\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 108.6206 - mae: 71.8713 - val_loss: 109.4406 - val_mae: 68.8245\n",
      "Epoch 317/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 110.4086 - mae: 69.7452\n",
      "Epoch 317: val_loss did not improve from 108.91731\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 109.1844 - mae: 72.5645 - val_loss: 109.3991 - val_mae: 69.7731\n",
      "Epoch 318/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.0787 - mae: 71.6786\n",
      "Epoch 318: val_loss improved from 108.91731 to 108.86585, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 108.8190 - mae: 72.4050 - val_loss: 108.8659 - val_mae: 69.0059\n",
      "Epoch 319/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 101.3797 - mae: 65.6546\n",
      "Epoch 319: val_loss improved from 108.86585 to 108.47210, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 108.0439 - mae: 71.2812 - val_loss: 108.4721 - val_mae: 70.2366\n",
      "Epoch 320/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 101.6776 - mae: 67.8624\n",
      "Epoch 320: val_loss did not improve from 108.47210\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 108.0722 - mae: 70.9149 - val_loss: 108.6573 - val_mae: 70.8188\n",
      "Epoch 321/400\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 108.6414 - mae: 70.8959\n",
      "Epoch 321: val_loss did not improve from 108.47210\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 107.7974 - mae: 70.4711 - val_loss: 108.8771 - val_mae: 71.7581\n",
      "Epoch 322/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 109.5388 - mae: 74.3374\n",
      "Epoch 322: val_loss did not improve from 108.47210\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 107.5924 - mae: 70.7629 - val_loss: 108.5890 - val_mae: 70.6046\n",
      "Epoch 323/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 105.8892 - mae: 70.0743\n",
      "Epoch 323: val_loss improved from 108.47210 to 108.09073, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 107.3953 - mae: 70.5822 - val_loss: 108.0907 - val_mae: 70.1473\n",
      "Epoch 324/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 115.8817 - mae: 74.1054\n",
      "Epoch 324: val_loss did not improve from 108.09073\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 107.3356 - mae: 70.3305 - val_loss: 108.4113 - val_mae: 70.8528\n",
      "Epoch 325/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.3420 - mae: 70.9495\n",
      "Epoch 325: val_loss did not improve from 108.09073\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 107.2739 - mae: 70.4975 - val_loss: 108.3917 - val_mae: 69.1358\n",
      "Epoch 326/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 110.8290 - mae: 69.6665\n",
      "Epoch 326: val_loss improved from 108.09073 to 107.80350, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 107.9366 - mae: 70.9513 - val_loss: 107.8035 - val_mae: 69.7523\n",
      "Epoch 327/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 99.5796 - mae: 66.8792\n",
      "Epoch 327: val_loss did not improve from 107.80350\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 107.8755 - mae: 70.6572 - val_loss: 108.3318 - val_mae: 70.8934\n",
      "Epoch 328/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 104.0762 - mae: 70.5844\n",
      "Epoch 328: val_loss did not improve from 107.80350\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 107.2813 - mae: 70.4585 - val_loss: 107.9795 - val_mae: 70.7861\n",
      "Epoch 329/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 106.3690 - mae: 69.9704\n",
      "Epoch 329: val_loss did not improve from 107.80350\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 107.1965 - mae: 70.4485 - val_loss: 107.9372 - val_mae: 70.5442\n",
      "Epoch 330/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 114.7172 - mae: 74.7374\n",
      "Epoch 330: val_loss did not improve from 107.80350\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 107.1142 - mae: 70.3880 - val_loss: 107.8103 - val_mae: 69.9022\n",
      "Epoch 331/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 103.3089 - mae: 67.8069\n",
      "Epoch 331: val_loss did not improve from 107.80350\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 106.9857 - mae: 70.7224 - val_loss: 107.8525 - val_mae: 68.7828\n",
      "Epoch 332/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 105.8961 - mae: 69.2712\n",
      "Epoch 332: val_loss did not improve from 107.80350\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 107.2497 - mae: 69.9013 - val_loss: 108.5145 - val_mae: 71.4514\n",
      "Epoch 333/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 104.1833 - mae: 69.1958\n",
      "Epoch 333: val_loss did not improve from 107.80350\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 107.0613 - mae: 70.0326 - val_loss: 109.9380 - val_mae: 73.0640\n",
      "Epoch 334/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 115.9601 - mae: 76.4451\n",
      "Epoch 334: val_loss did not improve from 107.80350\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 107.7183 - mae: 71.2217 - val_loss: 108.1588 - val_mae: 69.7580\n",
      "Epoch 335/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 109.4314 - mae: 70.0931\n",
      "Epoch 335: val_loss improved from 107.80350 to 107.73262, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 107.3397 - mae: 70.9797 - val_loss: 107.7326 - val_mae: 68.7596\n",
      "Epoch 336/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 111.0250 - mae: 71.5027\n",
      "Epoch 336: val_loss improved from 107.73262 to 107.19540, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 106.9223 - mae: 70.3504 - val_loss: 107.1954 - val_mae: 68.3721\n",
      "Epoch 337/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 111.3633 - mae: 69.7880\n",
      "Epoch 337: val_loss did not improve from 107.19540\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 107.1888 - mae: 70.3084 - val_loss: 107.4639 - val_mae: 69.2339\n",
      "Epoch 338/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 100.9736 - mae: 66.1920\n",
      "Epoch 338: val_loss did not improve from 107.19540\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 106.5324 - mae: 69.9534 - val_loss: 107.6501 - val_mae: 70.2264\n",
      "Epoch 339/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 108.0445 - mae: 69.6288\n",
      "Epoch 339: val_loss improved from 107.19540 to 107.02911, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 106.6708 - mae: 70.1713 - val_loss: 107.0291 - val_mae: 68.4617\n",
      "Epoch 340/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 112.5195 - mae: 71.8980\n",
      "Epoch 340: val_loss improved from 107.02911 to 106.76886, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 106.6059 - mae: 70.2565 - val_loss: 106.7689 - val_mae: 68.7309\n",
      "Epoch 341/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 96.6840 - mae: 64.2367\n",
      "Epoch 341: val_loss did not improve from 106.76886\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 106.4559 - mae: 69.6511 - val_loss: 108.1145 - val_mae: 71.4567\n",
      "Epoch 342/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 108.1250 - mae: 72.6817\n",
      "Epoch 342: val_loss did not improve from 106.76886\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 106.5171 - mae: 69.7838 - val_loss: 107.0206 - val_mae: 69.7578\n",
      "Epoch 343/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 103.3203 - mae: 68.3329\n",
      "Epoch 343: val_loss improved from 106.76886 to 106.64809, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 106.0900 - mae: 69.7848 - val_loss: 106.6481 - val_mae: 68.7405\n",
      "Epoch 344/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 102.3557 - mae: 67.1495\n",
      "Epoch 344: val_loss did not improve from 106.64809\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 106.0113 - mae: 69.4254 - val_loss: 106.7003 - val_mae: 68.7561\n",
      "Epoch 345/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 102.5214 - mae: 67.9576\n",
      "Epoch 345: val_loss did not improve from 106.64809\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 105.9447 - mae: 69.4406 - val_loss: 106.9606 - val_mae: 69.7437\n",
      "Epoch 346/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 102.9148 - mae: 66.7204\n",
      "Epoch 346: val_loss did not improve from 106.64809\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 105.9795 - mae: 69.5344 - val_loss: 106.9100 - val_mae: 68.0001\n",
      "Epoch 347/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.9265 - mae: 68.3018\n",
      "Epoch 347: val_loss did not improve from 106.64809\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 106.3520 - mae: 69.4555 - val_loss: 107.9607 - val_mae: 71.5838\n",
      "Epoch 348/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 101.7926 - mae: 69.3155\n",
      "Epoch 348: val_loss did not improve from 106.64809\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 106.2966 - mae: 69.7647 - val_loss: 108.0656 - val_mae: 71.7173\n",
      "Epoch 349/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 105.0262 - mae: 71.2672\n",
      "Epoch 349: val_loss did not improve from 106.64809\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 106.2135 - mae: 69.6767 - val_loss: 107.3107 - val_mae: 71.1022\n",
      "Epoch 350/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 104.3477 - mae: 70.3449\n",
      "Epoch 350: val_loss improved from 106.64809 to 106.40981, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 106.0447 - mae: 70.0473 - val_loss: 106.4098 - val_mae: 68.8948\n",
      "Epoch 351/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.3530 - mae: 71.0613\n",
      "Epoch 351: val_loss did not improve from 106.40981\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 105.5839 - mae: 69.6606 - val_loss: 106.6801 - val_mae: 69.5655\n",
      "Epoch 352/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 111.6687 - mae: 74.3609\n",
      "Epoch 352: val_loss did not improve from 106.40981\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 105.8767 - mae: 69.2163 - val_loss: 107.1672 - val_mae: 70.1262\n",
      "Epoch 353/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 109.4202 - mae: 71.7201\n",
      "Epoch 353: val_loss improved from 106.40981 to 106.21314, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 105.5485 - mae: 69.6346 - val_loss: 106.2131 - val_mae: 68.6284\n",
      "Epoch 354/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 100.7244 - mae: 66.0049\n",
      "Epoch 354: val_loss improved from 106.21314 to 106.04710, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 105.5017 - mae: 69.5376 - val_loss: 106.0471 - val_mae: 67.7528\n",
      "Epoch 355/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 101.6682 - mae: 66.1416\n",
      "Epoch 355: val_loss did not improve from 106.04710\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 106.1556 - mae: 69.5406 - val_loss: 106.4785 - val_mae: 67.6142\n",
      "Epoch 356/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.5231 - mae: 69.0296\n",
      "Epoch 356: val_loss improved from 106.04710 to 105.75802, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 105.9850 - mae: 69.3951 - val_loss: 105.7580 - val_mae: 67.4635\n",
      "Epoch 357/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 109.2545 - mae: 71.0198\n",
      "Epoch 357: val_loss did not improve from 105.75802\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 105.4610 - mae: 69.4177 - val_loss: 105.8870 - val_mae: 67.6677\n",
      "Epoch 358/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 116.0548 - mae: 73.4468\n",
      "Epoch 358: val_loss did not improve from 105.75802\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 105.2309 - mae: 69.3232 - val_loss: 106.8640 - val_mae: 66.9302\n",
      "Epoch 359/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 102.0918 - mae: 65.5685\n",
      "Epoch 359: val_loss improved from 105.75802 to 105.63083, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 105.7715 - mae: 69.7989 - val_loss: 105.6308 - val_mae: 67.4670\n",
      "Epoch 360/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 106.7226 - mae: 67.8900\n",
      "Epoch 360: val_loss did not improve from 105.63083\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 105.2151 - mae: 68.9342 - val_loss: 106.0428 - val_mae: 69.1747\n",
      "Epoch 361/400\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 105.8971 - mae: 68.7679\n",
      "Epoch 361: val_loss did not improve from 105.63083\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 105.8901 - mae: 69.3434 - val_loss: 106.0332 - val_mae: 68.7331\n",
      "Epoch 362/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 104.3537 - mae: 69.5986\n",
      "Epoch 362: val_loss did not improve from 105.63083\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 106.5097 - mae: 69.7935 - val_loss: 106.0943 - val_mae: 68.5948\n",
      "Epoch 363/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 98.6694 - mae: 66.2063\n",
      "Epoch 363: val_loss did not improve from 105.63083\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 106.0117 - mae: 69.0475 - val_loss: 105.8210 - val_mae: 68.7253\n",
      "Epoch 364/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 103.2654 - mae: 68.7880\n",
      "Epoch 364: val_loss did not improve from 105.63083\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 104.9907 - mae: 68.6707 - val_loss: 106.2960 - val_mae: 69.8627\n",
      "Epoch 365/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 103.2592 - mae: 68.4438\n",
      "Epoch 365: val_loss improved from 105.63083 to 105.59171, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 105.1548 - mae: 69.0434 - val_loss: 105.5917 - val_mae: 68.6076\n",
      "Epoch 366/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.6170 - mae: 68.2443\n",
      "Epoch 366: val_loss did not improve from 105.59171\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 104.6491 - mae: 68.9978 - val_loss: 106.1082 - val_mae: 66.4328\n",
      "Epoch 367/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 101.5792 - mae: 64.1459\n",
      "Epoch 367: val_loss improved from 105.59171 to 105.48586, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 105.9244 - mae: 69.7843 - val_loss: 105.4859 - val_mae: 66.9008\n",
      "Epoch 368/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 99.7961 - mae: 63.6078\n",
      "Epoch 368: val_loss improved from 105.48586 to 105.27718, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 104.4374 - mae: 68.7600 - val_loss: 105.2772 - val_mae: 67.1249\n",
      "Epoch 369/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 103.1467 - mae: 66.2160\n",
      "Epoch 369: val_loss improved from 105.27718 to 105.24274, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 104.8085 - mae: 68.7450 - val_loss: 105.2427 - val_mae: 67.2470\n",
      "Epoch 370/400\n",
      "7/7 [==============================] - ETA: 0s - loss: 104.6242 - mae: 68.0843\n",
      "Epoch 370: val_loss did not improve from 105.24274\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 104.6242 - mae: 68.0843 - val_loss: 107.0403 - val_mae: 71.1300\n",
      "Epoch 371/400\n",
      "7/7 [==============================] - ETA: 0s - loss: 105.0591 - mae: 68.5251\n",
      "Epoch 371: val_loss did not improve from 105.24274\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 105.0591 - mae: 68.5251 - val_loss: 107.3491 - val_mae: 71.4381\n",
      "Epoch 372/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 106.3175 - mae: 70.9899\n",
      "Epoch 372: val_loss did not improve from 105.24274\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 105.1695 - mae: 69.0687 - val_loss: 106.4412 - val_mae: 70.4012\n",
      "Epoch 373/400\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 104.4652 - mae: 68.5903\n",
      "Epoch 373: val_loss did not improve from 105.24274\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 104.4463 - mae: 68.5679 - val_loss: 105.6958 - val_mae: 69.0899\n",
      "Epoch 374/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 108.1180 - mae: 70.3985\n",
      "Epoch 374: val_loss improved from 105.24274 to 105.22206, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 104.7498 - mae: 68.9427 - val_loss: 105.2221 - val_mae: 68.5128\n",
      "Epoch 375/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 100.4899 - mae: 66.1144\n",
      "Epoch 375: val_loss improved from 105.22206 to 104.74297, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 104.4164 - mae: 68.8096 - val_loss: 104.7430 - val_mae: 67.2223\n",
      "Epoch 376/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 101.4099 - mae: 65.9867\n",
      "Epoch 376: val_loss improved from 104.74297 to 104.69261, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 104.4640 - mae: 68.9308 - val_loss: 104.6926 - val_mae: 66.9516\n",
      "Epoch 377/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 112.8940 - mae: 73.3304\n",
      "Epoch 377: val_loss did not improve from 104.69261\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 104.4534 - mae: 68.7352 - val_loss: 105.3687 - val_mae: 66.7452\n",
      "Epoch 378/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 106.1110 - mae: 68.4715\n",
      "Epoch 378: val_loss did not improve from 104.69261\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 104.6519 - mae: 69.1613 - val_loss: 105.1877 - val_mae: 66.2227\n",
      "Epoch 379/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.0198 - mae: 67.5515\n",
      "Epoch 379: val_loss did not improve from 104.69261\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 104.5552 - mae: 68.5452 - val_loss: 105.0150 - val_mae: 68.0702\n",
      "Epoch 380/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 113.2565 - mae: 73.2389\n",
      "Epoch 380: val_loss improved from 104.69261 to 104.46374, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 103.8775 - mae: 68.3532 - val_loss: 104.4637 - val_mae: 67.0678\n",
      "Epoch 381/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 101.0674 - mae: 67.1725\n",
      "Epoch 381: val_loss did not improve from 104.46374\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 103.6863 - mae: 68.2903 - val_loss: 104.7190 - val_mae: 67.0129\n",
      "Epoch 382/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 102.9942 - mae: 67.5827\n",
      "Epoch 382: val_loss did not improve from 104.46374\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 103.7328 - mae: 67.7149 - val_loss: 105.0909 - val_mae: 68.7435\n",
      "Epoch 383/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 104.6542 - mae: 68.4011\n",
      "Epoch 383: val_loss did not improve from 104.46374\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 103.6902 - mae: 67.8210 - val_loss: 105.3956 - val_mae: 68.9121\n",
      "Epoch 384/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 101.9204 - mae: 69.1434\n",
      "Epoch 384: val_loss did not improve from 104.46374\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 104.1152 - mae: 68.3724 - val_loss: 105.6540 - val_mae: 69.2756\n",
      "Epoch 385/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.0179 - mae: 71.3894\n",
      "Epoch 385: val_loss did not improve from 104.46374\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 104.2018 - mae: 68.6020 - val_loss: 105.8686 - val_mae: 69.2203\n",
      "Epoch 386/400\n",
      "5/7 [====================>.........] - ETA: 0s - loss: 104.5256 - mae: 68.9404\n",
      "Epoch 386: val_loss did not improve from 104.46374\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 104.0716 - mae: 68.6682 - val_loss: 104.5255 - val_mae: 67.9656\n",
      "Epoch 387/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 104.6151 - mae: 68.8963\n",
      "Epoch 387: val_loss did not improve from 104.46374\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 103.3040 - mae: 67.8210 - val_loss: 104.7832 - val_mae: 67.2278\n",
      "Epoch 388/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 107.3440 - mae: 69.6977\n",
      "Epoch 388: val_loss did not improve from 104.46374\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 103.8070 - mae: 68.1535 - val_loss: 104.7208 - val_mae: 67.3389\n",
      "Epoch 389/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 102.0818 - mae: 65.1215\n",
      "Epoch 389: val_loss did not improve from 104.46374\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 103.5303 - mae: 68.1524 - val_loss: 105.2587 - val_mae: 68.9003\n",
      "Epoch 390/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 104.2818 - mae: 68.0088\n",
      "Epoch 390: val_loss improved from 104.46374 to 104.36286, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 103.6254 - mae: 67.9354 - val_loss: 104.3629 - val_mae: 67.9701\n",
      "Epoch 391/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 102.3005 - mae: 68.1400\n",
      "Epoch 391: val_loss did not improve from 104.36286\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 103.8109 - mae: 68.2827 - val_loss: 105.1531 - val_mae: 68.8047\n",
      "Epoch 392/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 109.0113 - mae: 71.0918\n",
      "Epoch 392: val_loss did not improve from 104.36286\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 103.9346 - mae: 68.6379 - val_loss: 104.9733 - val_mae: 68.0506\n",
      "Epoch 393/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 104.1966 - mae: 68.0223\n",
      "Epoch 393: val_loss did not improve from 104.36286\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 103.9120 - mae: 68.6030 - val_loss: 104.7385 - val_mae: 67.5831\n",
      "Epoch 394/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 99.4186 - mae: 65.8755\n",
      "Epoch 394: val_loss did not improve from 104.36286\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 103.8304 - mae: 68.2761 - val_loss: 104.8451 - val_mae: 67.1471\n",
      "Epoch 395/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 104.9203 - mae: 69.2358\n",
      "Epoch 395: val_loss improved from 104.36286 to 104.20380, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 103.7716 - mae: 68.2465 - val_loss: 104.2038 - val_mae: 67.3370\n",
      "Epoch 396/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 104.2090 - mae: 68.2171\n",
      "Epoch 396: val_loss did not improve from 104.20380\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 103.0171 - mae: 67.3507 - val_loss: 105.0927 - val_mae: 69.3760\n",
      "Epoch 397/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 102.6534 - mae: 69.2649\n",
      "Epoch 397: val_loss did not improve from 104.20380\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 103.3984 - mae: 67.9833 - val_loss: 104.2756 - val_mae: 68.1671\n",
      "Epoch 398/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 108.3710 - mae: 71.3380\n",
      "Epoch 398: val_loss improved from 104.20380 to 103.82767, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 103.4508 - mae: 67.9995 - val_loss: 103.8277 - val_mae: 66.9368\n",
      "Epoch 399/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 100.2887 - mae: 66.7132\n",
      "Epoch 399: val_loss improved from 103.82767 to 103.75278, saving model to D:\\elice_python\\GAS_5\\pytest\\datasets\\bike_sharing\\model\\bike_best_model_oh.keras\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 103.0015 - mae: 67.7387 - val_loss: 103.7528 - val_mae: 66.9978\n",
      "Epoch 400/400\n",
      "1/7 [===>..........................] - ETA: 0s - loss: 105.0632 - mae: 70.3253\n",
      "Epoch 400: val_loss did not improve from 103.75278\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 103.1717 - mae: 67.4907 - val_loss: 103.9418 - val_mae: 65.8826\n"
     ]
    }
   ],
   "source": [
    "modelpath = os.path.join(path, 'model', 'bike_best_model_oh.keras')\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=modelpath,  \n",
    "                               monitor = 'val_loss', \n",
    "                               verbose=1,\n",
    "                               save_best_only = True\n",
    "                               )\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "          epochs=400, \n",
    "          batch_size=1024, \n",
    "          validation_split=0.2, \n",
    "          verbose=1,\n",
    "          callbacks = [checkpointer]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model(os.path.join(path, 'model','bike_best_model.keras'), custom_objects={'rmse': rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['mae']\n",
    "loss = history.history['loss']\n",
    "val_acc = history.history['val_mae']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = range(1,len(acc)+1)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "plt.title('T. and V. Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
