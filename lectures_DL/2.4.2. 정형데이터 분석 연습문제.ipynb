{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NATURE LANGUAGE\n",
    "### 연습문제 1\n",
    "- 초음파 Frequency로 광물-암석 예측하기\n",
    "- 광물과 암석을 종속변수로 하는 pytest/sonar.csv 파일로 이진분류를 수행하시오\n",
    "- 종속변수는 맨 우측 컬럼이며, 나머지는 모두 독립변수이다\n",
    "- 훈련 데이터와 테스트 데이터로 구분하여 테스트 데이터 정확도를 구하시오\n",
    "- 종속변수가 문자열임에 유의\n",
    "- 최종 모델을 Best 모델로 간주하여, 최종 모델을 불러 예측하시오\n",
    "    - (ModelCheckpoint를 사용하지 않음)\n",
    "    - 독립변수: 60개. 각 특정 주파수 대의 누적 에너지\n",
    "    - 종속변수: M-금속, R-암석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\elice_python\\\\GAS_5\\\\pytest'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = 'D:\\elice_python\\GAS_5\\pytest'\n",
    "\n",
    "os.chdir(path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>attribute_6</th>\n",
       "      <th>attribute_7</th>\n",
       "      <th>attribute_8</th>\n",
       "      <th>attribute_9</th>\n",
       "      <th>attribute_10</th>\n",
       "      <th>...</th>\n",
       "      <th>attribute_52</th>\n",
       "      <th>attribute_53</th>\n",
       "      <th>attribute_54</th>\n",
       "      <th>attribute_55</th>\n",
       "      <th>attribute_56</th>\n",
       "      <th>attribute_57</th>\n",
       "      <th>attribute_58</th>\n",
       "      <th>attribute_59</th>\n",
       "      <th>attribute_60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_1  attribute_2  attribute_3  attribute_4  attribute_5  \\\n",
       "0         0.02       0.0371       0.0428       0.0207       0.0954   \n",
       "\n",
       "   attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...  \\\n",
       "0       0.0986       0.1539       0.1601       0.3109        0.2111  ...   \n",
       "\n",
       "   attribute_52  attribute_53  attribute_54  attribute_55  attribute_56  \\\n",
       "0        0.0027        0.0065        0.0159        0.0072        0.0167   \n",
       "\n",
       "   attribute_57  attribute_58  attribute_59  attribute_60  Class  \n",
       "0         0.018        0.0084         0.009        0.0032   Rock  \n",
       "\n",
       "[1 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sonar.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   attribute_1   208 non-null    float64\n",
      " 1   attribute_2   208 non-null    float64\n",
      " 2   attribute_3   208 non-null    float64\n",
      " 3   attribute_4   208 non-null    float64\n",
      " 4   attribute_5   208 non-null    float64\n",
      " 5   attribute_6   208 non-null    float64\n",
      " 6   attribute_7   208 non-null    float64\n",
      " 7   attribute_8   208 non-null    float64\n",
      " 8   attribute_9   208 non-null    float64\n",
      " 9   attribute_10  208 non-null    float64\n",
      " 10  attribute_11  208 non-null    float64\n",
      " 11  attribute_12  208 non-null    float64\n",
      " 12  attribute_13  208 non-null    float64\n",
      " 13  attribute_14  208 non-null    float64\n",
      " 14  attribute_15  208 non-null    float64\n",
      " 15  attribute_16  208 non-null    float64\n",
      " 16  attribute_17  208 non-null    float64\n",
      " 17  attribute_18  208 non-null    float64\n",
      " 18  attribute_19  208 non-null    float64\n",
      " 19  attribute_20  208 non-null    float64\n",
      " 20  attribute_21  208 non-null    float64\n",
      " 21  attribute_22  208 non-null    float64\n",
      " 22  attribute_23  208 non-null    float64\n",
      " 23  attribute_24  208 non-null    float64\n",
      " 24  attribute_25  208 non-null    float64\n",
      " 25  attribute_26  208 non-null    float64\n",
      " 26  attribute_27  208 non-null    float64\n",
      " 27  attribute_28  208 non-null    float64\n",
      " 28  attribute_29  208 non-null    float64\n",
      " 29  attribute_30  208 non-null    float64\n",
      " 30  attribute_31  208 non-null    float64\n",
      " 31  attribute_32  208 non-null    float64\n",
      " 32  attribute_33  208 non-null    float64\n",
      " 33  attribute_34  208 non-null    float64\n",
      " 34  attribute_35  208 non-null    float64\n",
      " 35  attribute_36  208 non-null    float64\n",
      " 36  attribute_37  208 non-null    float64\n",
      " 37  attribute_38  208 non-null    float64\n",
      " 38  attribute_39  208 non-null    float64\n",
      " 39  attribute_40  208 non-null    float64\n",
      " 40  attribute_41  208 non-null    float64\n",
      " 41  attribute_42  208 non-null    float64\n",
      " 42  attribute_43  208 non-null    float64\n",
      " 43  attribute_44  208 non-null    float64\n",
      " 44  attribute_45  208 non-null    float64\n",
      " 45  attribute_46  208 non-null    float64\n",
      " 46  attribute_47  208 non-null    float64\n",
      " 47  attribute_48  208 non-null    float64\n",
      " 48  attribute_49  208 non-null    float64\n",
      " 49  attribute_50  208 non-null    float64\n",
      " 50  attribute_51  208 non-null    float64\n",
      " 51  attribute_52  208 non-null    float64\n",
      " 52  attribute_53  208 non-null    float64\n",
      " 53  attribute_54  208 non-null    float64\n",
      " 54  attribute_55  208 non-null    float64\n",
      " 55  attribute_56  208 non-null    float64\n",
      " 56  attribute_57  208 non-null    float64\n",
      " 57  attribute_58  208 non-null    float64\n",
      " 58  attribute_59  208 non-null    float64\n",
      " 59  attribute_60  208 non-null    float64\n",
      " 60  Class         208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rock', 'Mine'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Class == 'Rock', 'Class'] = 0\n",
    "df.loc[df.Class == 'Mine', 'Class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((208, 60), (208,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1].astype('int32')\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import  Sequential\n",
    "from keras.layers import  Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input((60,)))\n",
    "model.add(Dense(180, activation='relu', input_shape = (60,)))\n",
    "model.add(Dense(90, activation = 'relu'))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 180)               10980     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 90)                16290     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 30)                2730      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,321\n",
      "Trainable params: 30,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156, 60), (156,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 156 entries, 47 to 61\n",
      "Series name: Class\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "156 non-null    int32\n",
      "dtypes: int32(1)\n",
      "memory usage: 1.8 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 240, in __call__\n        self.build(y_pred)\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 182, in build\n        self._losses = tf.nest.map_structure(\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 353, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2649, in get\n        return deserialize(identifier)\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2603, in deserialize\n        return deserialize_keras_object(\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 769, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: binary_crossentrophy. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentrophy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      2\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m      3\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m156\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filedgb_r9xd.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 240, in __call__\n        self.build(y_pred)\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 182, in build\n        self._losses = tf.nest.map_structure(\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 353, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2649, in get\n        return deserialize(identifier)\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 2603, in deserialize\n        return deserialize_keras_object(\n    File \"c:\\Users\\Caelu\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 769, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: binary_crossentrophy. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=100, \n",
    "                    batch_size=156,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
