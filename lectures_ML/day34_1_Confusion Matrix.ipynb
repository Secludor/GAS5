{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "answer =    [1,1,0,1,0,0,1,0,0,0]\n",
    "predicted = [1,0,0,1,0,0,1,1,1,0]\n",
    "\n",
    "results = confusion_matrix(y_true=answer, y_pred=predicted)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = r'D:\\elice_python\\GAS_5\\pytest_machine'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0         18.0          10.4           123.0     1000.0           0.1180   \n",
      "1         20.6          17.8           133.0     1330.0           0.0847   \n",
      "2         19.7          21.3           130.0     1200.0           0.1100   \n",
      "3         11.4          20.4            77.6      386.0           0.1420   \n",
      "4         20.3          14.3           135.0     1300.0           0.1000   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0            0.2780          0.3000               0.1470          0.242   \n",
      "1            0.0786          0.0869               0.0702          0.181   \n",
      "2            0.1600          0.1970               0.1280          0.207   \n",
      "3            0.2840          0.2410               0.1050          0.260   \n",
      "4            0.1330          0.1980               0.1040          0.181   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                  0.0787  ...           17.3            185.0      2020.0   \n",
      "1                  0.0567  ...           23.4            159.0      1960.0   \n",
      "2                  0.0600  ...           25.5            153.0      1710.0   \n",
      "3                  0.0974  ...           26.5             98.9       568.0   \n",
      "4                  0.0588  ...           16.7            152.0      1580.0   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0             0.162              0.666            0.712                 0.265   \n",
      "1             0.124              0.187            0.242                 0.186   \n",
      "2             0.144              0.424            0.450                 0.243   \n",
      "3             0.210              0.866            0.687                 0.258   \n",
      "4             0.137              0.205            0.400                 0.163   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  benign  \n",
      "0           0.460                   0.1190     0.0  \n",
      "1           0.275                   0.0890     0.0  \n",
      "2           0.361                   0.0876     0.0  \n",
      "3           0.664                   0.1730     0.0  \n",
      "4           0.236                   0.0768     0.0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "(569, 31)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  benign                   569 non-null    float64\n",
      "dtypes: float64(31)\n",
      "memory usage: 137.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('cancer.csv')\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 스케일링 전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "prediction = svc.predict(X_test)\n",
    "print(prediction)\n",
    "print(svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44  9]\n",
      " [ 2 88]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_true=y_test, y_pred=prediction)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 스케일링 후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9790209790209791\n",
      "[[52  1]\n",
      " [ 2 88]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "mms.fit(X_train)\n",
    "X_train_mms = mms.transform(X_train)\n",
    "X_test_mms = mms.transform(X_test)\n",
    "\n",
    "svc_mms = SVC().fit(X_train_mms,y_train)\n",
    "\n",
    "prediction_mms = svc_mms.predict(X_test_mms)\n",
    "\n",
    "confusion_mms = confusion_matrix(y_true=y_test, y_pred=prediction_mms)\n",
    "\n",
    "print(svc_mms.score(X_test_mms, y_test))\n",
    "print(confusion_mms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 혼동행렬 요약\n",
    "- 혼동행렬을 요약하여 다음과 같이 하나의 score로 볼 수도 있다.\n",
    "\n",
    "- Accuracy(정확도) : 정확히 예측한 수(TP+TN)을 전체 샘플 수로 나눈 값이다. $$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "- Precision(정밀도) : 양성(1)으로 예측한 것(TP+FP) 중 진짜 양성(TP)의 비율\n",
    "\t- 양성에 대한 평가의 정확도로, 양성 예측도라고도 한다.$$Precision = \\frac{TP}{TP+FP}$$\n",
    "- Recall(재현율) : 전체 양성(TP+FN) 중 모델이 양성으로 분류한 것(TP)의 비율\n",
    "\t- 양성 샘플이 얼마나 식별되었는지를 보여준다. 민감도, 적중률이라고도 한다.$$Recall = \\frac{TP}{TP+FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9887640449438202\n",
      "0.9777777777777777\n",
      "0.9832402234636871\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_test, prediction_mms)\n",
    "recall = recall_score(y_test, prediction_mms)\n",
    "f1 = f1_score(y_test, prediction_mms)\n",
    "\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9072164948453608\n",
      "0.9777777777777777\n",
      "0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, prediction)\n",
    "recall = recall_score(y_test, prediction)\n",
    "f1 = f1_score(y_test, prediction)\n",
    "\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.98      0.97        53\n",
      "         1.0       0.99      0.98      0.98        90\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, prediction_mms)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n",
      "(150, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Sepal.Length  150 non-null    float64\n",
      " 1   Sepal.Width   150 non-null    float64\n",
      " 2   Petal.Length  150 non-null    float64\n",
      " 3   Petal.Width   150 non-null    float64\n",
      " 4   Species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('iris.csv')\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "prediction = tree.predict(X_test)\n",
    "print('accuracy : ', tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.9210526315789473\n",
      "confusion_matrix :\n",
      " [[12  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  2 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print('accuracy : ', accuracy_score(y_test, prediction))\n",
    "print('confusion_matrix :\\n', confusion_matrix(y_test, prediction) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다중분류 혼동행렬에서는 행이 정답값, 열이 예측값이다.\n",
    "\t- 순서는 알파벳, 숫자 정렬."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다중 분류에서의 Precision, Recall, F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def prf(y_true, y_pred, average):\n",
    "    precision = precision_score(y_true, y_pred, average=f'{average}')\n",
    "    recall = recall_score(y_true, y_pred, average=f'{average}')\n",
    "    f1 = f1_score(y_true, y_pred, average=f'{average}')\n",
    "    print(f'{average} precision : ', precision)\n",
    "    print(f'{average} recall : ', recall)\n",
    "    print(f'{average} f1 score : ', f1)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro precision :  0.9246031746031745\n",
      "macro recall :  0.923076923076923\n",
      "macro f1 score :  0.9229629629629629\n",
      "\n",
      "micro precision :  0.9210526315789473\n",
      "micro recall :  0.9210526315789473\n",
      "micro f1 score :  0.9210526315789473\n",
      "\n",
      "weighted precision :  0.9226190476190477\n",
      "weighted recall :  0.9210526315789473\n",
      "weighted f1 score :  0.9209356725146198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prf(y_test, prediction, 'macro')\n",
    "prf(y_test, prediction, 'micro')\n",
    "prf(y_test, prediction, 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       0.86      0.92      0.89        13\n",
      "   virginica       0.92      0.85      0.88        13\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.92      0.92      0.92        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, prediction)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
